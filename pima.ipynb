{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pima Indian Diabetes Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2019\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata = pd.read_csv('pima-indians-diabetes.csv')\n",
    "pdata.columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field Glucose: num 0-entries: 5\n",
      "field BloodPressure: num 0-entries: 35\n",
      "field SkinThickness: num 0-entries: 227\n",
      "field Insulin: num 0-entries: 374\n",
      "field BMI: num 0-entries: 11\n"
     ]
    }
   ],
   "source": [
    "zero_fields = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "#Loop thorugh each field and find how many entries have values in each field\n",
    "def check_zero_entries(data, fields):\n",
    "    for field in fields:\n",
    "        print('field %s: num 0-entries: %d' % (field, len(data.loc[ data[field] == 0, field ])))\n",
    "\n",
    "check_zero_entries(pdata, zero_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are instances where the values are 0\n",
    "2. Data preprocessing to impute avg of each column values for 0 emtries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
      "(576, 8)\n",
      "(192, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = list(pdata.columns.values)\n",
    "features.remove('Outcome')\n",
    "print(features)\n",
    "X = pdata[features]\n",
    "y = pdata['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_zero_field(data, field):\n",
    "    nonzero_vals = data.loc[data[field] != 0, field]\n",
    "    avg = np.sum(nonzero_vals) / len(nonzero_vals)\n",
    "    k = len(data.loc[ data[field] == 0, field])   # num of 0-entries\n",
    "    data.loc[ data[field] == 0, field ] = avg\n",
    "    print('Field: %s; fixed %d entries with value: %.3f' % (field, k, avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: Glucose; fixed 4 entries with value: 122.003\n",
      "Field: BloodPressure; fixed 25 entries with value: 72.846\n",
      "Field: SkinThickness; fixed 163 entries with value: 29.465\n",
      "Field: Insulin; fixed 270 entries with value: 158.464\n",
      "Field: BMI; fixed 8 entries with value: 32.663\n"
     ]
    }
   ],
   "source": [
    "for field in zero_fields:\n",
    "    impute_zero_field(X_train, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field Glucose: num 0-entries: 1\n",
      "field BloodPressure: num 0-entries: 10\n",
      "field SkinThickness: num 0-entries: 64\n",
      "field Insulin: num 0-entries: 104\n",
      "field BMI: num 0-entries: 3\n"
     ]
    }
   ],
   "source": [
    "check_zero_entries(X_test, zero_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test  = X_test.values\n",
    "y_test  = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/finra/anaconda/anaconda3/envs/finra_p36/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/usr/local/finra/anaconda/anaconda3/envs/finra_p36/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/finra/anaconda/anaconda3/envs/finra_p36/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "/usr/local/finra/anaconda/anaconda3/envs/finra_p36/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Train on 576 samples, validate on 192 samples\n",
      "Epoch 1/1000\n",
      "576/576 [==============================] - 0s 367us/step - loss: 0.6871 - accuracy: 0.6285 - val_loss: 0.6766 - val_accuracy: 0.6771\n",
      "Epoch 2/1000\n",
      "576/576 [==============================] - 0s 104us/step - loss: 0.6770 - accuracy: 0.6424 - val_loss: 0.6670 - val_accuracy: 0.6771\n",
      "Epoch 3/1000\n",
      "576/576 [==============================] - 0s 100us/step - loss: 0.6736 - accuracy: 0.6424 - val_loss: 0.6624 - val_accuracy: 0.6771\n",
      "Epoch 4/1000\n",
      "576/576 [==============================] - 0s 84us/step - loss: 0.6721 - accuracy: 0.6424 - val_loss: 0.6597 - val_accuracy: 0.6771\n",
      "Epoch 5/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6689 - accuracy: 0.6424 - val_loss: 0.6552 - val_accuracy: 0.6771\n",
      "Epoch 6/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6692 - accuracy: 0.6424 - val_loss: 0.6529 - val_accuracy: 0.6771\n",
      "Epoch 7/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.6657 - accuracy: 0.6424 - val_loss: 0.6485 - val_accuracy: 0.6771\n",
      "Epoch 8/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.6642 - accuracy: 0.6424 - val_loss: 0.6480 - val_accuracy: 0.6771\n",
      "Epoch 9/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.6614 - accuracy: 0.6458 - val_loss: 0.6434 - val_accuracy: 0.6719\n",
      "Epoch 10/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.6599 - accuracy: 0.6458 - val_loss: 0.6430 - val_accuracy: 0.6823\n",
      "Epoch 11/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6571 - accuracy: 0.6458 - val_loss: 0.6378 - val_accuracy: 0.6823\n",
      "Epoch 12/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6553 - accuracy: 0.6424 - val_loss: 0.6365 - val_accuracy: 0.6823\n",
      "Epoch 13/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6509 - accuracy: 0.6476 - val_loss: 0.6282 - val_accuracy: 0.6823\n",
      "Epoch 14/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6469 - accuracy: 0.6441 - val_loss: 0.6247 - val_accuracy: 0.6667\n",
      "Epoch 15/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.6449 - accuracy: 0.6528 - val_loss: 0.6114 - val_accuracy: 0.6719\n",
      "Epoch 16/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.6313 - accuracy: 0.6597 - val_loss: 0.5984 - val_accuracy: 0.6667\n",
      "Epoch 17/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.6210 - accuracy: 0.6632 - val_loss: 0.5880 - val_accuracy: 0.6875\n",
      "Epoch 18/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.6147 - accuracy: 0.6667 - val_loss: 0.5785 - val_accuracy: 0.7083\n",
      "Epoch 19/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.6103 - accuracy: 0.6858 - val_loss: 0.5725 - val_accuracy: 0.7240\n",
      "Epoch 20/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.6010 - accuracy: 0.6858 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
      "Epoch 21/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5899 - accuracy: 0.7083 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
      "Epoch 22/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.6041 - accuracy: 0.6615 - val_loss: 0.5808 - val_accuracy: 0.7240\n",
      "Epoch 23/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5824 - accuracy: 0.7118 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
      "Epoch 24/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5791 - accuracy: 0.7135 - val_loss: 0.5580 - val_accuracy: 0.7448\n",
      "Epoch 25/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5825 - accuracy: 0.6910 - val_loss: 0.5596 - val_accuracy: 0.7396\n",
      "Epoch 26/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5816 - accuracy: 0.7083 - val_loss: 0.6028 - val_accuracy: 0.6510\n",
      "Epoch 27/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5859 - accuracy: 0.6892 - val_loss: 0.5635 - val_accuracy: 0.7240\n",
      "Epoch 28/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5726 - accuracy: 0.7292 - val_loss: 0.5637 - val_accuracy: 0.7188\n",
      "Epoch 29/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5747 - accuracy: 0.7222 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
      "Epoch 30/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5727 - accuracy: 0.7240 - val_loss: 0.5513 - val_accuracy: 0.7292\n",
      "Epoch 31/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5696 - accuracy: 0.7257 - val_loss: 0.5616 - val_accuracy: 0.7135\n",
      "Epoch 32/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5735 - accuracy: 0.7292 - val_loss: 0.5600 - val_accuracy: 0.7135\n",
      "Epoch 33/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5629 - accuracy: 0.7361 - val_loss: 0.5494 - val_accuracy: 0.7292\n",
      "Epoch 34/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5629 - accuracy: 0.7170 - val_loss: 0.5715 - val_accuracy: 0.7135\n",
      "Epoch 35/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5735 - accuracy: 0.7153 - val_loss: 0.5567 - val_accuracy: 0.7135\n",
      "Epoch 36/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5614 - accuracy: 0.7222 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
      "Epoch 37/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5636 - accuracy: 0.7240 - val_loss: 0.5519 - val_accuracy: 0.7240\n",
      "Epoch 38/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5670 - accuracy: 0.7274 - val_loss: 0.5626 - val_accuracy: 0.7292\n",
      "Epoch 39/1000\n",
      "576/576 [==============================] - 0s 85us/step - loss: 0.5706 - accuracy: 0.7188 - val_loss: 0.5608 - val_accuracy: 0.7292\n",
      "Epoch 40/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5579 - accuracy: 0.7378 - val_loss: 0.5558 - val_accuracy: 0.7188\n",
      "Epoch 41/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5619 - accuracy: 0.7344 - val_loss: 0.5536 - val_accuracy: 0.7292\n",
      "Epoch 42/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5589 - accuracy: 0.7222 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
      "Epoch 43/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5600 - accuracy: 0.7205 - val_loss: 0.5616 - val_accuracy: 0.7292\n",
      "Epoch 44/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5607 - accuracy: 0.7309 - val_loss: 0.5527 - val_accuracy: 0.7188\n",
      "Epoch 45/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5560 - accuracy: 0.7309 - val_loss: 0.5573 - val_accuracy: 0.7292\n",
      "Epoch 46/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5581 - accuracy: 0.7396 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
      "Epoch 47/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5580 - accuracy: 0.7257 - val_loss: 0.5439 - val_accuracy: 0.7448\n",
      "Epoch 48/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5530 - accuracy: 0.7344 - val_loss: 0.5493 - val_accuracy: 0.7240\n",
      "Epoch 49/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5541 - accuracy: 0.7413 - val_loss: 0.5552 - val_accuracy: 0.7344\n",
      "Epoch 50/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5549 - accuracy: 0.7205 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
      "Epoch 51/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5515 - accuracy: 0.7413 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
      "Epoch 52/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5501 - accuracy: 0.7326 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
      "Epoch 53/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5553 - accuracy: 0.7118 - val_loss: 0.5411 - val_accuracy: 0.7396\n",
      "Epoch 54/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5533 - accuracy: 0.7292 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
      "Epoch 55/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5490 - accuracy: 0.7465 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 56/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5499 - accuracy: 0.7344 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
      "Epoch 57/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5516 - accuracy: 0.7274 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 58/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5470 - accuracy: 0.7396 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 59/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5507 - accuracy: 0.7188 - val_loss: 0.5665 - val_accuracy: 0.7031\n",
      "Epoch 60/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5499 - accuracy: 0.7378 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 61/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5429 - accuracy: 0.7483 - val_loss: 0.5429 - val_accuracy: 0.7240\n",
      "Epoch 62/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5520 - accuracy: 0.7326 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
      "Epoch 63/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5494 - accuracy: 0.7431 - val_loss: 0.5448 - val_accuracy: 0.7396\n",
      "Epoch 64/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5445 - accuracy: 0.7483 - val_loss: 0.5428 - val_accuracy: 0.7240\n",
      "Epoch 65/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5478 - accuracy: 0.7240 - val_loss: 0.5357 - val_accuracy: 0.7396\n",
      "Epoch 66/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5461 - accuracy: 0.7274 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
      "Epoch 67/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5485 - accuracy: 0.7396 - val_loss: 0.5358 - val_accuracy: 0.7396\n",
      "Epoch 68/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5400 - accuracy: 0.7361 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
      "Epoch 69/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5395 - accuracy: 0.7396 - val_loss: 0.5378 - val_accuracy: 0.7292\n",
      "Epoch 70/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5435 - accuracy: 0.7309 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 71/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5390 - accuracy: 0.7378 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
      "Epoch 72/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5368 - accuracy: 0.7413 - val_loss: 0.5371 - val_accuracy: 0.7396\n",
      "Epoch 73/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5372 - accuracy: 0.7431 - val_loss: 0.5359 - val_accuracy: 0.7292\n",
      "Epoch 74/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5364 - accuracy: 0.7448 - val_loss: 0.5302 - val_accuracy: 0.7448\n",
      "Epoch 75/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5360 - accuracy: 0.7517 - val_loss: 0.5303 - val_accuracy: 0.7448\n",
      "Epoch 76/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5377 - accuracy: 0.7431 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 77/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5374 - accuracy: 0.7448 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5368 - accuracy: 0.7309 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 79/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5294 - accuracy: 0.7465 - val_loss: 0.5317 - val_accuracy: 0.7344\n",
      "Epoch 80/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5324 - accuracy: 0.7413 - val_loss: 0.5332 - val_accuracy: 0.7344\n",
      "Epoch 81/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5332 - accuracy: 0.7396 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5302 - accuracy: 0.7465 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 83/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5334 - accuracy: 0.7396 - val_loss: 0.5347 - val_accuracy: 0.7500\n",
      "Epoch 84/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5353 - accuracy: 0.7483 - val_loss: 0.5396 - val_accuracy: 0.7396\n",
      "Epoch 85/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5265 - accuracy: 0.7413 - val_loss: 0.5291 - val_accuracy: 0.7344\n",
      "Epoch 86/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5253 - accuracy: 0.7483 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 87/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5294 - accuracy: 0.7431 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
      "Epoch 88/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5328 - accuracy: 0.7448 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5269 - accuracy: 0.7517 - val_loss: 0.5271 - val_accuracy: 0.7396\n",
      "Epoch 90/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.5214 - accuracy: 0.7552 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 91/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5211 - accuracy: 0.7500 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 92/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5244 - accuracy: 0.7344 - val_loss: 0.5225 - val_accuracy: 0.7344\n",
      "Epoch 93/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5187 - accuracy: 0.7535 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 94/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5213 - accuracy: 0.7535 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 95/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5254 - accuracy: 0.7344 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 96/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.5233 - accuracy: 0.7500 - val_loss: 0.5219 - val_accuracy: 0.7448\n",
      "Epoch 97/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.5176 - accuracy: 0.7517 - val_loss: 0.5215 - val_accuracy: 0.7448\n",
      "Epoch 98/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5214 - accuracy: 0.7413 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
      "Epoch 99/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5152 - accuracy: 0.7431 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 100/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5145 - accuracy: 0.7448 - val_loss: 0.5194 - val_accuracy: 0.7552\n",
      "Epoch 101/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5153 - accuracy: 0.7448 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 102/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5146 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.7448\n",
      "Epoch 103/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5109 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 104/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5124 - accuracy: 0.7517 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 105/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5155 - accuracy: 0.7448 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 106/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5127 - accuracy: 0.7517 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 107/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5159 - accuracy: 0.7483 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 108/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5080 - accuracy: 0.7552 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 109/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5060 - accuracy: 0.7517 - val_loss: 0.5173 - val_accuracy: 0.7396\n",
      "Epoch 110/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5050 - accuracy: 0.7552 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 111/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5090 - accuracy: 0.7361 - val_loss: 0.5222 - val_accuracy: 0.7552\n",
      "Epoch 112/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5017 - accuracy: 0.7500 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 113/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5012 - accuracy: 0.7639 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
      "Epoch 114/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5024 - accuracy: 0.7535 - val_loss: 0.5177 - val_accuracy: 0.7396\n",
      "Epoch 115/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5024 - accuracy: 0.7552 - val_loss: 0.5217 - val_accuracy: 0.7448\n",
      "Epoch 116/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 117/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5091 - accuracy: 0.7483 - val_loss: 0.5183 - val_accuracy: 0.7396\n",
      "Epoch 118/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5033 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7396\n",
      "Epoch 119/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5044 - accuracy: 0.7552 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 120/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5029 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.7500\n",
      "Epoch 121/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5006 - accuracy: 0.7535 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 122/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5009 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 123/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4982 - accuracy: 0.7587 - val_loss: 0.5308 - val_accuracy: 0.7396\n",
      "Epoch 124/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4997 - accuracy: 0.7587 - val_loss: 0.5178 - val_accuracy: 0.7396\n",
      "Epoch 125/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4936 - accuracy: 0.7708 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 126/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
      "Epoch 127/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.5013 - accuracy: 0.7535 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 128/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4907 - accuracy: 0.7674 - val_loss: 0.5214 - val_accuracy: 0.7500\n",
      "Epoch 129/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4911 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 130/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4882 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 131/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4936 - accuracy: 0.7517 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4901 - accuracy: 0.7674 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 133/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4903 - accuracy: 0.7639 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 134/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4897 - accuracy: 0.7743 - val_loss: 0.5228 - val_accuracy: 0.7604\n",
      "Epoch 135/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4937 - accuracy: 0.7778 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 136/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4879 - accuracy: 0.7743 - val_loss: 0.5210 - val_accuracy: 0.7656\n",
      "Epoch 137/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4886 - accuracy: 0.7622 - val_loss: 0.5206 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4840 - accuracy: 0.7726 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
      "Epoch 139/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
      "Epoch 140/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
      "Epoch 141/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 142/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4819 - accuracy: 0.7639 - val_loss: 0.5403 - val_accuracy: 0.7344\n",
      "Epoch 143/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4836 - accuracy: 0.7708 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.5185 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4822 - accuracy: 0.7743 - val_loss: 0.5261 - val_accuracy: 0.7448\n",
      "Epoch 146/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4958 - accuracy: 0.7622 - val_loss: 0.5292 - val_accuracy: 0.7448\n",
      "Epoch 147/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4794 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
      "Epoch 148/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4843 - accuracy: 0.7552 - val_loss: 0.5288 - val_accuracy: 0.7448\n",
      "Epoch 149/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4820 - accuracy: 0.7622 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 150/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4773 - accuracy: 0.7760 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 151/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4779 - accuracy: 0.7812 - val_loss: 0.5281 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4895 - accuracy: 0.7587 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
      "Epoch 153/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.5032 - accuracy: 0.7760 - val_loss: 0.5375 - val_accuracy: 0.7396\n",
      "Epoch 154/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4795 - accuracy: 0.7743 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 155/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 156/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4759 - accuracy: 0.7830 - val_loss: 0.5193 - val_accuracy: 0.7500\n",
      "Epoch 157/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4838 - accuracy: 0.7760 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 158/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4735 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 159/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4839 - accuracy: 0.7569 - val_loss: 0.5206 - val_accuracy: 0.7292\n",
      "Epoch 160/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 161/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4839 - accuracy: 0.7812 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 162/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4882 - accuracy: 0.7587 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 163/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.5248 - val_accuracy: 0.7500\n",
      "Epoch 164/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4828 - accuracy: 0.7743 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 165/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.5342 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4738 - accuracy: 0.7656 - val_loss: 0.5227 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4706 - accuracy: 0.7812 - val_loss: 0.5246 - val_accuracy: 0.7500\n",
      "Epoch 168/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 169/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.5305 - val_accuracy: 0.7448\n",
      "Epoch 170/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.5161 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.5284 - val_accuracy: 0.7500\n",
      "Epoch 172/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4757 - accuracy: 0.7778 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 174/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4761 - accuracy: 0.7674 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 175/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 176/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4714 - accuracy: 0.7639 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 177/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
      "Epoch 178/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4720 - accuracy: 0.7899 - val_loss: 0.5466 - val_accuracy: 0.7240\n",
      "Epoch 179/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4890 - accuracy: 0.7674 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
      "Epoch 180/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4988 - accuracy: 0.7674 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 181/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4874 - accuracy: 0.7569 - val_loss: 0.5267 - val_accuracy: 0.7448\n",
      "Epoch 182/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.5037 - accuracy: 0.7483 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
      "Epoch 183/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4707 - accuracy: 0.7917 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 184/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4767 - accuracy: 0.7830 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 185/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4859 - accuracy: 0.7587 - val_loss: 0.5238 - val_accuracy: 0.7500\n",
      "Epoch 186/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4637 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 187/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4738 - accuracy: 0.7795 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 188/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4806 - accuracy: 0.7656 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 189/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4684 - accuracy: 0.7812 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
      "Epoch 190/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4700 - accuracy: 0.7656 - val_loss: 0.5245 - val_accuracy: 0.7396\n",
      "Epoch 191/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4868 - accuracy: 0.7535 - val_loss: 0.5154 - val_accuracy: 0.7188\n",
      "Epoch 192/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 193/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 194/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4621 - accuracy: 0.7847 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
      "Epoch 195/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.5267 - val_accuracy: 0.7500\n",
      "Epoch 196/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.5250 - val_accuracy: 0.7448\n",
      "Epoch 197/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 198/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4685 - accuracy: 0.7604 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 199/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.5579 - val_accuracy: 0.7083\n",
      "Epoch 200/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4745 - accuracy: 0.7674 - val_loss: 0.5325 - val_accuracy: 0.7396\n",
      "Epoch 201/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4626 - accuracy: 0.7830 - val_loss: 0.5199 - val_accuracy: 0.7188\n",
      "Epoch 202/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
      "Epoch 203/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 204/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4658 - accuracy: 0.7847 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 205/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.5235 - val_accuracy: 0.7292\n",
      "Epoch 206/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 207/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4588 - accuracy: 0.7847 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 208/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4627 - accuracy: 0.7830 - val_loss: 0.5200 - val_accuracy: 0.7083\n",
      "Epoch 209/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4653 - accuracy: 0.7726 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 210/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4585 - accuracy: 0.7882 - val_loss: 0.5303 - val_accuracy: 0.7500\n",
      "Epoch 211/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.5274 - val_accuracy: 0.7500\n",
      "Epoch 212/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4723 - accuracy: 0.7656 - val_loss: 0.5281 - val_accuracy: 0.7396\n",
      "Epoch 213/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4591 - accuracy: 0.7865 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
      "Epoch 214/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7396\n",
      "Epoch 215/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
      "Epoch 216/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.5280 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4625 - accuracy: 0.7743 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 218/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4647 - accuracy: 0.7865 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 219/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 220/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 221/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4534 - accuracy: 0.7708 - val_loss: 0.5264 - val_accuracy: 0.7500\n",
      "Epoch 222/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4550 - accuracy: 0.7830 - val_loss: 0.5239 - val_accuracy: 0.7344\n",
      "Epoch 223/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4537 - accuracy: 0.7917 - val_loss: 0.5192 - val_accuracy: 0.7135\n",
      "Epoch 224/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.5244 - val_accuracy: 0.7396\n",
      "Epoch 225/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 226/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 227/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
      "Epoch 228/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4548 - accuracy: 0.7865 - val_loss: 0.5249 - val_accuracy: 0.7552\n",
      "Epoch 229/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5274 - val_accuracy: 0.7344\n",
      "Epoch 230/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.5348 - val_accuracy: 0.7396\n",
      "Epoch 231/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4594 - accuracy: 0.7847 - val_loss: 0.5323 - val_accuracy: 0.7292\n",
      "Epoch 232/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4634 - accuracy: 0.7812 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 233/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4546 - accuracy: 0.7708 - val_loss: 0.5320 - val_accuracy: 0.7396\n",
      "Epoch 234/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4535 - accuracy: 0.7830 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
      "Epoch 235/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
      "Epoch 236/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 237/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 238/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5266 - val_accuracy: 0.7292\n",
      "Epoch 239/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.5274 - val_accuracy: 0.7396\n",
      "Epoch 240/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.5089 - val_accuracy: 0.7500\n",
      "Epoch 241/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.5570 - val_accuracy: 0.7135\n",
      "Epoch 242/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4579 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 243/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4724 - accuracy: 0.7691 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 244/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4605 - accuracy: 0.7674 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
      "Epoch 245/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5254 - val_accuracy: 0.7500\n",
      "Epoch 246/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 247/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4474 - accuracy: 0.7882 - val_loss: 0.5261 - val_accuracy: 0.7135\n",
      "Epoch 248/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4588 - accuracy: 0.7899 - val_loss: 0.5308 - val_accuracy: 0.7448\n",
      "Epoch 249/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4529 - accuracy: 0.7847 - val_loss: 0.5218 - val_accuracy: 0.7135\n",
      "Epoch 250/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4618 - accuracy: 0.7743 - val_loss: 0.5199 - val_accuracy: 0.7344\n",
      "Epoch 251/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.5362 - val_accuracy: 0.7448\n",
      "Epoch 252/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4524 - accuracy: 0.7830 - val_loss: 0.5322 - val_accuracy: 0.7396\n",
      "Epoch 253/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 254/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.5351 - val_accuracy: 0.7396\n",
      "Epoch 255/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4561 - accuracy: 0.7726 - val_loss: 0.5268 - val_accuracy: 0.7500\n",
      "Epoch 256/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4491 - accuracy: 0.7795 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
      "Epoch 257/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4707 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7396\n",
      "Epoch 258/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 259/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.5299 - val_accuracy: 0.7344\n",
      "Epoch 260/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4656 - accuracy: 0.7656 - val_loss: 0.5201 - val_accuracy: 0.7292\n",
      "Epoch 261/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4575 - accuracy: 0.7934 - val_loss: 0.5406 - val_accuracy: 0.7135\n",
      "Epoch 262/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.5197 - val_accuracy: 0.7604\n",
      "Epoch 264/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
      "Epoch 265/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5198 - val_accuracy: 0.7188\n",
      "Epoch 266/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4709 - accuracy: 0.7778 - val_loss: 0.5497 - val_accuracy: 0.7135\n",
      "Epoch 267/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 268/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4574 - accuracy: 0.7708 - val_loss: 0.5310 - val_accuracy: 0.7396\n",
      "Epoch 270/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4522 - accuracy: 0.7899 - val_loss: 0.5280 - val_accuracy: 0.7396\n",
      "Epoch 271/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 272/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4574 - accuracy: 0.7795 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 274/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4488 - accuracy: 0.7917 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 275/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4491 - accuracy: 0.7812 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 277/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4462 - accuracy: 0.7917 - val_loss: 0.5361 - val_accuracy: 0.7292\n",
      "Epoch 278/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4529 - accuracy: 0.7830 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
      "Epoch 279/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 280/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
      "Epoch 281/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4577 - accuracy: 0.7865 - val_loss: 0.5202 - val_accuracy: 0.7292\n",
      "Epoch 282/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4470 - accuracy: 0.7986 - val_loss: 0.5192 - val_accuracy: 0.7292\n",
      "Epoch 283/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 284/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4505 - accuracy: 0.7934 - val_loss: 0.5556 - val_accuracy: 0.7188\n",
      "Epoch 285/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4515 - accuracy: 0.7812 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 286/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.5332 - val_accuracy: 0.7396\n",
      "Epoch 287/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5179 - val_accuracy: 0.7552\n",
      "Epoch 288/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4507 - accuracy: 0.7882 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 290/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4525 - accuracy: 0.7917 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 291/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4518 - accuracy: 0.7726 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 292/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5338 - val_accuracy: 0.7344\n",
      "Epoch 293/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.5201 - val_accuracy: 0.7552\n",
      "Epoch 294/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4476 - accuracy: 0.7865 - val_loss: 0.5179 - val_accuracy: 0.7604\n",
      "Epoch 295/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7396\n",
      "Epoch 296/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.5213 - val_accuracy: 0.7604\n",
      "Epoch 297/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 298/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4455 - accuracy: 0.7847 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 299/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4615 - accuracy: 0.7708 - val_loss: 0.5277 - val_accuracy: 0.7344\n",
      "Epoch 300/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 301/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 302/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4459 - accuracy: 0.7847 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 303/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
      "Epoch 304/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4503 - accuracy: 0.7812 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
      "Epoch 305/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4541 - accuracy: 0.7847 - val_loss: 0.5242 - val_accuracy: 0.7552\n",
      "Epoch 306/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7396\n",
      "Epoch 307/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4533 - accuracy: 0.7795 - val_loss: 0.5263 - val_accuracy: 0.7396\n",
      "Epoch 308/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.5337 - val_accuracy: 0.7240\n",
      "Epoch 309/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4556 - accuracy: 0.7847 - val_loss: 0.5264 - val_accuracy: 0.7448\n",
      "Epoch 310/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4406 - accuracy: 0.7917 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5391 - val_accuracy: 0.7240\n",
      "Epoch 312/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5464 - val_accuracy: 0.7188\n",
      "Epoch 313/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 314/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4432 - accuracy: 0.7865 - val_loss: 0.5286 - val_accuracy: 0.7396\n",
      "Epoch 315/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4609 - accuracy: 0.7708 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
      "Epoch 316/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.5530 - val_accuracy: 0.7240\n",
      "Epoch 317/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5278 - val_accuracy: 0.7344\n",
      "Epoch 318/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4437 - accuracy: 0.7812 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 319/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4546 - accuracy: 0.7795 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4427 - accuracy: 0.7917 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 321/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5235 - val_accuracy: 0.7448\n",
      "Epoch 322/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7240\n",
      "Epoch 324/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.5171 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4544 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 326/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4441 - accuracy: 0.7812 - val_loss: 0.5549 - val_accuracy: 0.7240\n",
      "Epoch 327/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4545 - accuracy: 0.7830 - val_loss: 0.5237 - val_accuracy: 0.7344\n",
      "Epoch 328/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4501 - accuracy: 0.7726 - val_loss: 0.5327 - val_accuracy: 0.7396\n",
      "Epoch 329/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 330/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4556 - accuracy: 0.7674 - val_loss: 0.5272 - val_accuracy: 0.7240\n",
      "Epoch 331/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.5361 - val_accuracy: 0.7396\n",
      "Epoch 332/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 333/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.5205 - val_accuracy: 0.7448\n",
      "Epoch 334/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
      "Epoch 335/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
      "Epoch 336/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4515 - accuracy: 0.7847 - val_loss: 0.5214 - val_accuracy: 0.7604\n",
      "Epoch 337/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 338/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5296 - val_accuracy: 0.7396\n",
      "Epoch 339/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4460 - accuracy: 0.7726 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 340/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.5324 - val_accuracy: 0.7240\n",
      "Epoch 341/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4579 - accuracy: 0.7882 - val_loss: 0.5337 - val_accuracy: 0.7292\n",
      "Epoch 342/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4523 - accuracy: 0.7899 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 343/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4459 - accuracy: 0.7917 - val_loss: 0.5286 - val_accuracy: 0.7448\n",
      "Epoch 344/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5399 - val_accuracy: 0.7188\n",
      "Epoch 345/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4565 - accuracy: 0.7812 - val_loss: 0.5622 - val_accuracy: 0.7188\n",
      "Epoch 346/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4571 - accuracy: 0.7986 - val_loss: 0.5337 - val_accuracy: 0.7188\n",
      "Epoch 347/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4731 - accuracy: 0.7552 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 348/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.5382 - val_accuracy: 0.7396\n",
      "Epoch 349/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4558 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4536 - accuracy: 0.7726 - val_loss: 0.5371 - val_accuracy: 0.7344\n",
      "Epoch 351/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.5148 - val_accuracy: 0.7135\n",
      "Epoch 352/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4460 - accuracy: 0.7830 - val_loss: 0.5220 - val_accuracy: 0.7552\n",
      "Epoch 353/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4529 - accuracy: 0.7726 - val_loss: 0.5338 - val_accuracy: 0.7292\n",
      "Epoch 354/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
      "Epoch 355/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4518 - accuracy: 0.7812 - val_loss: 0.5646 - val_accuracy: 0.7135\n",
      "Epoch 356/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.5298 - val_accuracy: 0.7344\n",
      "Epoch 357/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4446 - accuracy: 0.7778 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
      "Epoch 358/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4574 - accuracy: 0.7812 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
      "Epoch 359/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 360/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4410 - accuracy: 0.7795 - val_loss: 0.5394 - val_accuracy: 0.7083\n",
      "Epoch 361/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5289 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.5535 - val_accuracy: 0.7292\n",
      "Epoch 363/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 364/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5434 - val_accuracy: 0.7292\n",
      "Epoch 365/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4511 - accuracy: 0.7812 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
      "Epoch 366/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.5294 - val_accuracy: 0.7292\n",
      "Epoch 367/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4447 - accuracy: 0.8003 - val_loss: 0.5390 - val_accuracy: 0.7448\n",
      "Epoch 368/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4530 - accuracy: 0.7760 - val_loss: 0.5204 - val_accuracy: 0.7292\n",
      "Epoch 369/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.5261 - val_accuracy: 0.7292\n",
      "Epoch 370/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.5519 - val_accuracy: 0.7188\n",
      "Epoch 371/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4571 - accuracy: 0.7812 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
      "Epoch 372/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4497 - accuracy: 0.7760 - val_loss: 0.5288 - val_accuracy: 0.7240\n",
      "Epoch 373/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5505 - val_accuracy: 0.7240\n",
      "Epoch 374/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4442 - accuracy: 0.7865 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 375/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4441 - accuracy: 0.7795 - val_loss: 0.5349 - val_accuracy: 0.7240\n",
      "Epoch 376/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4457 - accuracy: 0.7865 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
      "Epoch 378/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4542 - accuracy: 0.7830 - val_loss: 0.5566 - val_accuracy: 0.7135\n",
      "Epoch 379/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.5345 - val_accuracy: 0.7188\n",
      "Epoch 380/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4422 - accuracy: 0.7951 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 381/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4445 - accuracy: 0.7795 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
      "Epoch 382/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4462 - accuracy: 0.7830 - val_loss: 0.5305 - val_accuracy: 0.7240\n",
      "Epoch 383/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4472 - accuracy: 0.7899 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
      "Epoch 384/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4445 - accuracy: 0.7795 - val_loss: 0.5498 - val_accuracy: 0.7344\n",
      "Epoch 385/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 386/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4500 - accuracy: 0.7760 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
      "Epoch 387/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4633 - accuracy: 0.7760 - val_loss: 0.5501 - val_accuracy: 0.7240\n",
      "Epoch 388/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
      "Epoch 389/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4394 - accuracy: 0.7882 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 390/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4408 - accuracy: 0.7812 - val_loss: 0.5308 - val_accuracy: 0.7135\n",
      "Epoch 391/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 392/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
      "Epoch 393/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5381 - val_accuracy: 0.7292\n",
      "Epoch 394/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4460 - accuracy: 0.7865 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 395/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4604 - accuracy: 0.7917 - val_loss: 0.5667 - val_accuracy: 0.7188\n",
      "Epoch 396/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4484 - accuracy: 0.7847 - val_loss: 0.5333 - val_accuracy: 0.7188\n",
      "Epoch 397/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5338 - val_accuracy: 0.7188\n",
      "Epoch 398/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5632 - val_accuracy: 0.7240\n",
      "Epoch 399/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4536 - accuracy: 0.7917 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
      "Epoch 400/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4449 - accuracy: 0.7847 - val_loss: 0.5561 - val_accuracy: 0.7240\n",
      "Epoch 401/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.5434 - val_accuracy: 0.7135\n",
      "Epoch 402/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4514 - accuracy: 0.7951 - val_loss: 0.5395 - val_accuracy: 0.7292\n",
      "Epoch 403/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4465 - accuracy: 0.7847 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
      "Epoch 404/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.5326 - val_accuracy: 0.7188\n",
      "Epoch 405/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
      "Epoch 406/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5328 - val_accuracy: 0.7240\n",
      "Epoch 407/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 408/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.5599 - val_accuracy: 0.7240\n",
      "Epoch 409/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4505 - accuracy: 0.7778 - val_loss: 0.5476 - val_accuracy: 0.7083\n",
      "Epoch 410/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4473 - accuracy: 0.7865 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
      "Epoch 411/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.5363 - val_accuracy: 0.7344\n",
      "Epoch 412/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4470 - accuracy: 0.7674 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 413/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4439 - accuracy: 0.7899 - val_loss: 0.5353 - val_accuracy: 0.7135\n",
      "Epoch 414/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4533 - accuracy: 0.7812 - val_loss: 0.5302 - val_accuracy: 0.7344\n",
      "Epoch 415/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5399 - val_accuracy: 0.7083\n",
      "Epoch 416/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.5587 - val_accuracy: 0.7292\n",
      "Epoch 417/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5391 - val_accuracy: 0.7448\n",
      "Epoch 418/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.5446 - val_accuracy: 0.7083\n",
      "Epoch 419/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4597 - accuracy: 0.7760 - val_loss: 0.5384 - val_accuracy: 0.7240\n",
      "Epoch 420/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4424 - accuracy: 0.7865 - val_loss: 0.5419 - val_accuracy: 0.7292\n",
      "Epoch 421/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4443 - accuracy: 0.7778 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 422/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4487 - accuracy: 0.7847 - val_loss: 0.5412 - val_accuracy: 0.7344\n",
      "Epoch 423/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
      "Epoch 424/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5447 - val_accuracy: 0.7396\n",
      "Epoch 425/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5484 - val_accuracy: 0.7344\n",
      "Epoch 426/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4438 - accuracy: 0.7812 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 427/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4610 - accuracy: 0.7951 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
      "Epoch 428/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 429/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5486 - val_accuracy: 0.7396\n",
      "Epoch 430/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.5353 - val_accuracy: 0.7396\n",
      "Epoch 431/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 432/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4456 - accuracy: 0.7726 - val_loss: 0.5513 - val_accuracy: 0.7083\n",
      "Epoch 433/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5413 - val_accuracy: 0.7031\n",
      "Epoch 434/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.5477 - val_accuracy: 0.6979\n",
      "Epoch 435/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4650 - accuracy: 0.7639 - val_loss: 0.5481 - val_accuracy: 0.7396\n",
      "Epoch 436/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4513 - accuracy: 0.7795 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4417 - accuracy: 0.7847 - val_loss: 0.5702 - val_accuracy: 0.7188\n",
      "Epoch 438/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5464 - val_accuracy: 0.7188\n",
      "Epoch 439/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4415 - accuracy: 0.7865 - val_loss: 0.5320 - val_accuracy: 0.7292\n",
      "Epoch 440/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4519 - accuracy: 0.7795 - val_loss: 0.5764 - val_accuracy: 0.7292\n",
      "Epoch 441/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.5403 - val_accuracy: 0.7396\n",
      "Epoch 442/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5470 - val_accuracy: 0.7188\n",
      "Epoch 443/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4624 - accuracy: 0.7639 - val_loss: 0.5375 - val_accuracy: 0.7344\n",
      "Epoch 444/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.5429 - val_accuracy: 0.7240\n",
      "Epoch 445/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.5428 - val_accuracy: 0.7031\n",
      "Epoch 446/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4462 - accuracy: 0.7986 - val_loss: 0.5299 - val_accuracy: 0.7292\n",
      "Epoch 447/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4435 - accuracy: 0.7899 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
      "Epoch 448/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4467 - accuracy: 0.7795 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
      "Epoch 449/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
      "Epoch 450/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4503 - accuracy: 0.7899 - val_loss: 0.5451 - val_accuracy: 0.7292\n",
      "Epoch 451/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4417 - accuracy: 0.7760 - val_loss: 0.5451 - val_accuracy: 0.7083\n",
      "Epoch 452/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.5546 - val_accuracy: 0.7240\n",
      "Epoch 453/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4469 - accuracy: 0.7778 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 454/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.5391 - val_accuracy: 0.7396\n",
      "Epoch 455/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4382 - accuracy: 0.7917 - val_loss: 0.5421 - val_accuracy: 0.7240\n",
      "Epoch 456/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.5379 - val_accuracy: 0.7135\n",
      "Epoch 457/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
      "Epoch 458/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5370 - val_accuracy: 0.7344\n",
      "Epoch 459/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5508 - val_accuracy: 0.7344\n",
      "Epoch 460/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4461 - accuracy: 0.7795 - val_loss: 0.5573 - val_accuracy: 0.7292\n",
      "Epoch 461/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4491 - accuracy: 0.7778 - val_loss: 0.5404 - val_accuracy: 0.7396\n",
      "Epoch 462/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5473 - val_accuracy: 0.7240\n",
      "Epoch 463/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
      "Epoch 464/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4468 - accuracy: 0.7778 - val_loss: 0.5499 - val_accuracy: 0.7031\n",
      "Epoch 465/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4481 - accuracy: 0.7812 - val_loss: 0.5606 - val_accuracy: 0.7240\n",
      "Epoch 466/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4517 - accuracy: 0.7899 - val_loss: 0.5513 - val_accuracy: 0.7031\n",
      "Epoch 467/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4564 - accuracy: 0.7830 - val_loss: 0.5902 - val_accuracy: 0.7188\n",
      "Epoch 468/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.5490 - val_accuracy: 0.7031\n",
      "Epoch 469/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7292\n",
      "Epoch 470/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4409 - accuracy: 0.7882 - val_loss: 0.5454 - val_accuracy: 0.7135\n",
      "Epoch 471/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4443 - accuracy: 0.7986 - val_loss: 0.5501 - val_accuracy: 0.7292\n",
      "Epoch 472/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5378 - val_accuracy: 0.7135\n",
      "Epoch 473/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.5672 - val_accuracy: 0.7292\n",
      "Epoch 474/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4470 - accuracy: 0.7778 - val_loss: 0.5406 - val_accuracy: 0.7188\n",
      "Epoch 475/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.5397 - val_accuracy: 0.7292\n",
      "Epoch 476/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4387 - accuracy: 0.7865 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 477/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.5518 - val_accuracy: 0.7188\n",
      "Epoch 478/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.5486 - val_accuracy: 0.7031\n",
      "Epoch 479/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.5448 - val_accuracy: 0.7448\n",
      "Epoch 480/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4426 - accuracy: 0.7899 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 481/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4521 - accuracy: 0.7812 - val_loss: 0.5510 - val_accuracy: 0.7083\n",
      "Epoch 482/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
      "Epoch 483/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4492 - accuracy: 0.7795 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
      "Epoch 484/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.5648 - val_accuracy: 0.7188\n",
      "Epoch 485/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4459 - accuracy: 0.7795 - val_loss: 0.5479 - val_accuracy: 0.7083\n",
      "Epoch 486/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.5539 - val_accuracy: 0.7031\n",
      "Epoch 487/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
      "Epoch 488/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.5409 - val_accuracy: 0.7292\n",
      "Epoch 489/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4530 - accuracy: 0.7743 - val_loss: 0.5558 - val_accuracy: 0.7396\n",
      "Epoch 490/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4424 - accuracy: 0.7969 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
      "Epoch 491/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5430 - val_accuracy: 0.7292\n",
      "Epoch 492/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.5491 - val_accuracy: 0.7031\n",
      "Epoch 493/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5469 - val_accuracy: 0.7188\n",
      "Epoch 494/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4425 - accuracy: 0.7865 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
      "Epoch 495/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
      "Epoch 496/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.5649 - val_accuracy: 0.7396\n",
      "Epoch 497/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4423 - accuracy: 0.7830 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
      "Epoch 498/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4443 - accuracy: 0.7847 - val_loss: 0.5455 - val_accuracy: 0.7396\n",
      "Epoch 499/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4424 - accuracy: 0.7917 - val_loss: 0.5443 - val_accuracy: 0.7396\n",
      "Epoch 500/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5658 - val_accuracy: 0.7344\n",
      "Epoch 501/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
      "Epoch 502/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4379 - accuracy: 0.7865 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
      "Epoch 503/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4392 - accuracy: 0.7969 - val_loss: 0.5447 - val_accuracy: 0.7188\n",
      "Epoch 504/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
      "Epoch 505/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5570 - val_accuracy: 0.7396\n",
      "Epoch 506/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5549 - val_accuracy: 0.7188\n",
      "Epoch 507/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4503 - accuracy: 0.7847 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
      "Epoch 508/1000\n",
      "576/576 [==============================] - 0s 88us/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
      "Epoch 509/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4445 - accuracy: 0.7795 - val_loss: 0.5607 - val_accuracy: 0.7083\n",
      "Epoch 510/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4638 - accuracy: 0.7743 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
      "Epoch 511/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.5667 - val_accuracy: 0.7240\n",
      "Epoch 512/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4417 - accuracy: 0.7812 - val_loss: 0.5632 - val_accuracy: 0.7292\n",
      "Epoch 513/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4559 - accuracy: 0.7639 - val_loss: 0.5522 - val_accuracy: 0.7135\n",
      "Epoch 514/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4487 - accuracy: 0.7969 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 515/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4467 - accuracy: 0.7865 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
      "Epoch 516/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4514 - accuracy: 0.7726 - val_loss: 0.5554 - val_accuracy: 0.7031\n",
      "Epoch 517/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4475 - accuracy: 0.7969 - val_loss: 0.5414 - val_accuracy: 0.7135\n",
      "Epoch 518/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4542 - accuracy: 0.7674 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
      "Epoch 519/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
      "Epoch 520/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.5631 - val_accuracy: 0.7083\n",
      "Epoch 521/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4482 - accuracy: 0.7899 - val_loss: 0.5518 - val_accuracy: 0.7135\n",
      "Epoch 522/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.5504 - val_accuracy: 0.7292\n",
      "Epoch 523/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4501 - accuracy: 0.7708 - val_loss: 0.5529 - val_accuracy: 0.7135\n",
      "Epoch 524/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5426 - val_accuracy: 0.7292\n",
      "Epoch 525/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.5555 - val_accuracy: 0.7344\n",
      "Epoch 526/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5496 - val_accuracy: 0.7292\n",
      "Epoch 527/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4390 - accuracy: 0.7917 - val_loss: 0.5499 - val_accuracy: 0.7344\n",
      "Epoch 528/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 529/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4419 - accuracy: 0.8003 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 530/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4461 - accuracy: 0.7934 - val_loss: 0.5407 - val_accuracy: 0.7240\n",
      "Epoch 531/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
      "Epoch 532/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5461 - val_accuracy: 0.7240\n",
      "Epoch 533/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5398 - val_accuracy: 0.7240\n",
      "Epoch 534/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5475 - val_accuracy: 0.7083\n",
      "Epoch 535/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5446 - val_accuracy: 0.7292\n",
      "Epoch 536/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4427 - accuracy: 0.7847 - val_loss: 0.5515 - val_accuracy: 0.7344\n",
      "Epoch 537/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4404 - accuracy: 0.7899 - val_loss: 0.5528 - val_accuracy: 0.7240\n",
      "Epoch 538/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5731 - val_accuracy: 0.7240\n",
      "Epoch 539/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.5527 - val_accuracy: 0.7031\n",
      "Epoch 540/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4657 - accuracy: 0.7639 - val_loss: 0.5461 - val_accuracy: 0.7135\n",
      "Epoch 541/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5516 - val_accuracy: 0.7083\n",
      "Epoch 542/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.5458 - val_accuracy: 0.7292\n",
      "Epoch 543/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.5427 - val_accuracy: 0.7344\n",
      "Epoch 544/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5553 - val_accuracy: 0.7344\n",
      "Epoch 545/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4393 - accuracy: 0.7951 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 546/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.5480 - val_accuracy: 0.7135\n",
      "Epoch 547/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.5543 - val_accuracy: 0.7240\n",
      "Epoch 548/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4389 - accuracy: 0.7882 - val_loss: 0.5517 - val_accuracy: 0.7240\n",
      "Epoch 549/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4418 - accuracy: 0.7882 - val_loss: 0.5568 - val_accuracy: 0.7240\n",
      "Epoch 550/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4395 - accuracy: 0.7847 - val_loss: 0.5575 - val_accuracy: 0.7344\n",
      "Epoch 551/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4343 - accuracy: 0.7917 - val_loss: 0.5460 - val_accuracy: 0.7188\n",
      "Epoch 552/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4515 - accuracy: 0.7934 - val_loss: 0.5576 - val_accuracy: 0.6979\n",
      "Epoch 553/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4615 - accuracy: 0.7691 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
      "Epoch 554/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 555/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
      "Epoch 556/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4399 - accuracy: 0.7795 - val_loss: 0.5607 - val_accuracy: 0.7292\n",
      "Epoch 557/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4406 - accuracy: 0.7899 - val_loss: 0.5617 - val_accuracy: 0.7344\n",
      "Epoch 558/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
      "Epoch 559/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4543 - accuracy: 0.7743 - val_loss: 0.5563 - val_accuracy: 0.7240\n",
      "Epoch 560/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.5742 - val_accuracy: 0.7240\n",
      "Epoch 561/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5507 - val_accuracy: 0.7135\n",
      "Epoch 562/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5557 - val_accuracy: 0.7240\n",
      "Epoch 563/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 564/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5458 - val_accuracy: 0.7240\n",
      "Epoch 565/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4858 - accuracy: 0.7743 - val_loss: 0.5678 - val_accuracy: 0.7188\n",
      "Epoch 566/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5414 - val_accuracy: 0.7292\n",
      "Epoch 567/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4402 - accuracy: 0.7847 - val_loss: 0.5487 - val_accuracy: 0.7031\n",
      "Epoch 568/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.5415 - val_accuracy: 0.7188\n",
      "Epoch 569/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4455 - accuracy: 0.7951 - val_loss: 0.5504 - val_accuracy: 0.7344\n",
      "Epoch 570/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
      "Epoch 571/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5390 - val_accuracy: 0.7188\n",
      "Epoch 572/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4410 - accuracy: 0.7899 - val_loss: 0.5355 - val_accuracy: 0.7292\n",
      "Epoch 573/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4440 - accuracy: 0.7812 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
      "Epoch 574/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4445 - accuracy: 0.7847 - val_loss: 0.5393 - val_accuracy: 0.7344\n",
      "Epoch 575/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.5618 - val_accuracy: 0.7396\n",
      "Epoch 576/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4548 - accuracy: 0.7604 - val_loss: 0.5436 - val_accuracy: 0.7135\n",
      "Epoch 577/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4521 - accuracy: 0.7917 - val_loss: 0.5447 - val_accuracy: 0.7135\n",
      "Epoch 578/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.5532 - val_accuracy: 0.7292\n",
      "Epoch 579/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4437 - accuracy: 0.7934 - val_loss: 0.5447 - val_accuracy: 0.7240\n",
      "Epoch 580/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5478 - val_accuracy: 0.7240\n",
      "Epoch 581/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5693 - val_accuracy: 0.7240\n",
      "Epoch 582/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.5596 - val_accuracy: 0.7292\n",
      "Epoch 583/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4458 - accuracy: 0.7865 - val_loss: 0.5509 - val_accuracy: 0.6979\n",
      "Epoch 584/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 585/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.5742 - val_accuracy: 0.7240\n",
      "Epoch 586/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
      "Epoch 587/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.5421 - val_accuracy: 0.7188\n",
      "Epoch 588/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4373 - accuracy: 0.7847 - val_loss: 0.5571 - val_accuracy: 0.7188\n",
      "Epoch 589/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5668 - val_accuracy: 0.7344\n",
      "Epoch 590/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 591/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
      "Epoch 592/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.5470 - val_accuracy: 0.7135\n",
      "Epoch 593/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
      "Epoch 594/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4413 - accuracy: 0.7882 - val_loss: 0.5578 - val_accuracy: 0.7240\n",
      "Epoch 595/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4551 - accuracy: 0.7899 - val_loss: 0.5607 - val_accuracy: 0.6979\n",
      "Epoch 596/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.5487 - val_accuracy: 0.7188\n",
      "Epoch 597/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
      "Epoch 598/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5566 - val_accuracy: 0.7344\n",
      "Epoch 599/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5452 - val_accuracy: 0.7188\n",
      "Epoch 600/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.5509 - val_accuracy: 0.7031\n",
      "Epoch 601/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4448 - accuracy: 0.7795 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
      "Epoch 602/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
      "Epoch 603/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5491 - val_accuracy: 0.7031\n",
      "Epoch 604/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.5573 - val_accuracy: 0.6979\n",
      "Epoch 605/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4466 - accuracy: 0.7865 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 606/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 607/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.5445 - val_accuracy: 0.7135\n",
      "Epoch 608/1000\n",
      "576/576 [==============================] - 0s 83us/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5435 - val_accuracy: 0.7292\n",
      "Epoch 609/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4480 - accuracy: 0.7812 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
      "Epoch 610/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5405 - val_accuracy: 0.7188\n",
      "Epoch 611/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
      "Epoch 612/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4483 - accuracy: 0.7812 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
      "Epoch 613/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.5445 - val_accuracy: 0.7344\n",
      "Epoch 614/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4426 - accuracy: 0.7795 - val_loss: 0.5476 - val_accuracy: 0.7240\n",
      "Epoch 615/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4391 - accuracy: 0.7882 - val_loss: 0.5392 - val_accuracy: 0.7188\n",
      "Epoch 616/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5431 - val_accuracy: 0.7292\n",
      "Epoch 617/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4526 - accuracy: 0.7899 - val_loss: 0.5526 - val_accuracy: 0.7292\n",
      "Epoch 618/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5395 - val_accuracy: 0.7240\n",
      "Epoch 619/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4491 - accuracy: 0.7865 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
      "Epoch 620/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.5407 - val_accuracy: 0.7292\n",
      "Epoch 621/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4423 - accuracy: 0.7795 - val_loss: 0.5522 - val_accuracy: 0.7292\n",
      "Epoch 622/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.5550 - val_accuracy: 0.7292\n",
      "Epoch 623/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4453 - accuracy: 0.7830 - val_loss: 0.5344 - val_accuracy: 0.7292\n",
      "Epoch 624/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5420 - val_accuracy: 0.7292\n",
      "Epoch 625/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.5425 - val_accuracy: 0.7083\n",
      "Epoch 626/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5498 - val_accuracy: 0.7240\n",
      "Epoch 627/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4418 - accuracy: 0.7899 - val_loss: 0.5355 - val_accuracy: 0.7344\n",
      "Epoch 628/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
      "Epoch 629/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
      "Epoch 630/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4420 - accuracy: 0.7882 - val_loss: 0.5480 - val_accuracy: 0.6979\n",
      "Epoch 631/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5401 - val_accuracy: 0.7188\n",
      "Epoch 632/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5507 - val_accuracy: 0.7240\n",
      "Epoch 633/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4405 - accuracy: 0.7899 - val_loss: 0.5602 - val_accuracy: 0.7292\n",
      "Epoch 634/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5481 - val_accuracy: 0.7188\n",
      "Epoch 635/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4371 - accuracy: 0.7969 - val_loss: 0.5715 - val_accuracy: 0.7292\n",
      "Epoch 636/1000\n",
      "576/576 [==============================] - 0s 82us/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5438 - val_accuracy: 0.7083\n",
      "Epoch 637/1000\n",
      "576/576 [==============================] - 0s 81us/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5497 - val_accuracy: 0.7240\n",
      "Epoch 638/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4473 - accuracy: 0.7934 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
      "Epoch 639/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4500 - accuracy: 0.7917 - val_loss: 0.5535 - val_accuracy: 0.7083\n",
      "Epoch 640/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5498 - val_accuracy: 0.7135\n",
      "Epoch 641/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4437 - accuracy: 0.7899 - val_loss: 0.5529 - val_accuracy: 0.7188\n",
      "Epoch 642/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5588 - val_accuracy: 0.7188\n",
      "Epoch 643/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4477 - accuracy: 0.7882 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
      "Epoch 644/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4464 - accuracy: 0.7986 - val_loss: 0.5494 - val_accuracy: 0.7083\n",
      "Epoch 645/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.5567 - val_accuracy: 0.7292\n",
      "Epoch 646/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5801 - val_accuracy: 0.6927\n",
      "Epoch 647/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5566 - val_accuracy: 0.7344\n",
      "Epoch 648/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4429 - accuracy: 0.7830 - val_loss: 0.5508 - val_accuracy: 0.7344\n",
      "Epoch 649/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5678 - val_accuracy: 0.7188\n",
      "Epoch 650/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4385 - accuracy: 0.7882 - val_loss: 0.5646 - val_accuracy: 0.7188\n",
      "Epoch 651/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5510 - val_accuracy: 0.7031\n",
      "Epoch 652/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.5644 - val_accuracy: 0.7240\n",
      "Epoch 653/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
      "Epoch 654/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5660 - val_accuracy: 0.7031\n",
      "Epoch 655/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
      "Epoch 656/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
      "Epoch 657/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4356 - accuracy: 0.8038 - val_loss: 0.5516 - val_accuracy: 0.7292\n",
      "Epoch 658/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4375 - accuracy: 0.7865 - val_loss: 0.5469 - val_accuracy: 0.7240\n",
      "Epoch 659/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4485 - accuracy: 0.7708 - val_loss: 0.5894 - val_accuracy: 0.7188\n",
      "Epoch 660/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5617 - val_accuracy: 0.6979\n",
      "Epoch 661/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5525 - val_accuracy: 0.7135\n",
      "Epoch 662/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5487 - val_accuracy: 0.7083\n",
      "Epoch 663/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5501 - val_accuracy: 0.7344\n",
      "Epoch 664/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4433 - accuracy: 0.7917 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
      "Epoch 665/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4403 - accuracy: 0.7830 - val_loss: 0.5494 - val_accuracy: 0.7135\n",
      "Epoch 666/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.5495 - val_accuracy: 0.7083\n",
      "Epoch 667/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.5549 - val_accuracy: 0.7240\n",
      "Epoch 668/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.5411 - val_accuracy: 0.7292\n",
      "Epoch 669/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.5405 - val_accuracy: 0.7188\n",
      "Epoch 670/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4454 - accuracy: 0.7847 - val_loss: 0.5549 - val_accuracy: 0.7292\n",
      "Epoch 671/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4388 - accuracy: 0.7882 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
      "Epoch 672/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5444 - val_accuracy: 0.7292\n",
      "Epoch 673/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5431 - val_accuracy: 0.7240\n",
      "Epoch 674/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5377 - val_accuracy: 0.7083\n",
      "Epoch 675/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4377 - accuracy: 0.7778 - val_loss: 0.5461 - val_accuracy: 0.7188\n",
      "Epoch 676/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4469 - accuracy: 0.7795 - val_loss: 0.5534 - val_accuracy: 0.7344\n",
      "Epoch 677/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.5481 - val_accuracy: 0.7292\n",
      "Epoch 678/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4420 - accuracy: 0.7899 - val_loss: 0.5382 - val_accuracy: 0.7292\n",
      "Epoch 679/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.5544 - val_accuracy: 0.7240\n",
      "Epoch 680/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4322 - accuracy: 0.7917 - val_loss: 0.5572 - val_accuracy: 0.7292\n",
      "Epoch 681/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4376 - accuracy: 0.7795 - val_loss: 0.5401 - val_accuracy: 0.7292\n",
      "Epoch 682/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4461 - accuracy: 0.7778 - val_loss: 0.5427 - val_accuracy: 0.7240\n",
      "Epoch 683/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.5613 - val_accuracy: 0.7240\n",
      "Epoch 684/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.5443 - val_accuracy: 0.7292\n",
      "Epoch 685/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4328 - accuracy: 0.7917 - val_loss: 0.5482 - val_accuracy: 0.7083\n",
      "Epoch 686/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4529 - accuracy: 0.8003 - val_loss: 0.5530 - val_accuracy: 0.7448\n",
      "Epoch 687/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.5568 - val_accuracy: 0.7344\n",
      "Epoch 688/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.5460 - val_accuracy: 0.7344\n",
      "Epoch 689/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4355 - accuracy: 0.7917 - val_loss: 0.5722 - val_accuracy: 0.7292\n",
      "Epoch 690/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4546 - accuracy: 0.7899 - val_loss: 0.5550 - val_accuracy: 0.7188\n",
      "Epoch 691/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.5470 - val_accuracy: 0.7135\n",
      "Epoch 692/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4360 - accuracy: 0.7917 - val_loss: 0.5511 - val_accuracy: 0.7344\n",
      "Epoch 693/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4372 - accuracy: 0.7986 - val_loss: 0.5468 - val_accuracy: 0.7344\n",
      "Epoch 694/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5429 - val_accuracy: 0.7292\n",
      "Epoch 695/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4405 - accuracy: 0.7830 - val_loss: 0.5463 - val_accuracy: 0.7292\n",
      "Epoch 696/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7083\n",
      "Epoch 697/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4421 - accuracy: 0.7830 - val_loss: 0.5519 - val_accuracy: 0.7083\n",
      "Epoch 698/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4422 - accuracy: 0.7882 - val_loss: 0.5533 - val_accuracy: 0.7292\n",
      "Epoch 699/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4351 - accuracy: 0.7882 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
      "Epoch 700/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4341 - accuracy: 0.7865 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
      "Epoch 701/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4441 - accuracy: 0.7917 - val_loss: 0.5464 - val_accuracy: 0.7135\n",
      "Epoch 702/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4652 - accuracy: 0.7969 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
      "Epoch 703/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 704/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5463 - val_accuracy: 0.7083\n",
      "Epoch 705/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
      "Epoch 706/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.5517 - val_accuracy: 0.7292\n",
      "Epoch 707/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5429 - val_accuracy: 0.7188\n",
      "Epoch 708/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.5496 - val_accuracy: 0.7031\n",
      "Epoch 709/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4511 - accuracy: 0.7656 - val_loss: 0.5479 - val_accuracy: 0.7188\n",
      "Epoch 710/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4367 - accuracy: 0.7830 - val_loss: 0.5576 - val_accuracy: 0.7188\n",
      "Epoch 711/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.5393 - val_accuracy: 0.7188\n",
      "Epoch 712/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.5639 - val_accuracy: 0.7292\n",
      "Epoch 713/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4465 - accuracy: 0.7934 - val_loss: 0.5547 - val_accuracy: 0.7031\n",
      "Epoch 714/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.5485 - val_accuracy: 0.7188\n",
      "Epoch 715/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5477 - val_accuracy: 0.7188\n",
      "Epoch 716/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4380 - accuracy: 0.7830 - val_loss: 0.5422 - val_accuracy: 0.7135\n",
      "Epoch 717/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4401 - accuracy: 0.7812 - val_loss: 0.5481 - val_accuracy: 0.7240\n",
      "Epoch 718/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
      "Epoch 719/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4452 - accuracy: 0.7778 - val_loss: 0.5399 - val_accuracy: 0.7240\n",
      "Epoch 720/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4356 - accuracy: 0.7899 - val_loss: 0.5507 - val_accuracy: 0.7083\n",
      "Epoch 721/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4369 - accuracy: 0.7969 - val_loss: 0.5490 - val_accuracy: 0.7188\n",
      "Epoch 722/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4388 - accuracy: 0.7951 - val_loss: 0.5768 - val_accuracy: 0.7240\n",
      "Epoch 723/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5489 - val_accuracy: 0.7031\n",
      "Epoch 724/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4432 - accuracy: 0.7899 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
      "Epoch 725/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5601 - val_accuracy: 0.7240\n",
      "Epoch 726/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4359 - accuracy: 0.7899 - val_loss: 0.5434 - val_accuracy: 0.7083\n",
      "Epoch 727/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4369 - accuracy: 0.7917 - val_loss: 0.5775 - val_accuracy: 0.7240\n",
      "Epoch 728/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4417 - accuracy: 0.7795 - val_loss: 0.5536 - val_accuracy: 0.7083\n",
      "Epoch 729/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4402 - accuracy: 0.7830 - val_loss: 0.5612 - val_accuracy: 0.7240\n",
      "Epoch 730/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4348 - accuracy: 0.7865 - val_loss: 0.5606 - val_accuracy: 0.7240\n",
      "Epoch 731/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5778 - val_accuracy: 0.7240\n",
      "Epoch 732/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4415 - accuracy: 0.7899 - val_loss: 0.5638 - val_accuracy: 0.7240\n",
      "Epoch 733/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.5500 - val_accuracy: 0.7031\n",
      "Epoch 734/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4525 - accuracy: 0.7830 - val_loss: 0.5538 - val_accuracy: 0.7240\n",
      "Epoch 735/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4416 - accuracy: 0.7865 - val_loss: 0.5540 - val_accuracy: 0.7292\n",
      "Epoch 736/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.5454 - val_accuracy: 0.7292\n",
      "Epoch 737/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.5621 - val_accuracy: 0.7292\n",
      "Epoch 738/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4478 - accuracy: 0.7726 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
      "Epoch 739/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4410 - accuracy: 0.7882 - val_loss: 0.5638 - val_accuracy: 0.7188\n",
      "Epoch 740/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4532 - accuracy: 0.7795 - val_loss: 0.5582 - val_accuracy: 0.7188\n",
      "Epoch 741/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 742/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4439 - accuracy: 0.7865 - val_loss: 0.5466 - val_accuracy: 0.7188\n",
      "Epoch 743/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.5510 - val_accuracy: 0.7292\n",
      "Epoch 744/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4357 - accuracy: 0.7899 - val_loss: 0.5471 - val_accuracy: 0.7188\n",
      "Epoch 745/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
      "Epoch 746/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5855 - val_accuracy: 0.7240\n",
      "Epoch 747/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4551 - accuracy: 0.7934 - val_loss: 0.5479 - val_accuracy: 0.7344\n",
      "Epoch 748/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4516 - accuracy: 0.7882 - val_loss: 0.5461 - val_accuracy: 0.7344\n",
      "Epoch 749/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4397 - accuracy: 0.7865 - val_loss: 0.5543 - val_accuracy: 0.7240\n",
      "Epoch 750/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4382 - accuracy: 0.7865 - val_loss: 0.5508 - val_accuracy: 0.7083\n",
      "Epoch 751/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.5415 - val_accuracy: 0.7240\n",
      "Epoch 752/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4406 - accuracy: 0.7969 - val_loss: 0.5553 - val_accuracy: 0.7240\n",
      "Epoch 753/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4400 - accuracy: 0.7951 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
      "Epoch 754/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4471 - accuracy: 0.7778 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
      "Epoch 755/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
      "Epoch 756/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5734 - val_accuracy: 0.7188\n",
      "Epoch 757/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4355 - accuracy: 0.8021 - val_loss: 0.5477 - val_accuracy: 0.7135\n",
      "Epoch 758/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
      "Epoch 759/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4424 - accuracy: 0.7899 - val_loss: 0.5748 - val_accuracy: 0.7240\n",
      "Epoch 760/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4457 - accuracy: 0.7830 - val_loss: 0.5593 - val_accuracy: 0.7188\n",
      "Epoch 761/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5423 - val_accuracy: 0.7292\n",
      "Epoch 762/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4411 - accuracy: 0.7865 - val_loss: 0.5425 - val_accuracy: 0.7240\n",
      "Epoch 763/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
      "Epoch 764/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4353 - accuracy: 0.7899 - val_loss: 0.5510 - val_accuracy: 0.7135\n",
      "Epoch 765/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.5436 - val_accuracy: 0.7240\n",
      "Epoch 766/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.5516 - val_accuracy: 0.7240\n",
      "Epoch 767/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4403 - accuracy: 0.7899 - val_loss: 0.5470 - val_accuracy: 0.7135\n",
      "Epoch 768/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5477 - val_accuracy: 0.7135\n",
      "Epoch 769/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.5493 - val_accuracy: 0.7188\n",
      "Epoch 770/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4362 - accuracy: 0.7899 - val_loss: 0.5502 - val_accuracy: 0.7188\n",
      "Epoch 771/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.5605 - val_accuracy: 0.6979\n",
      "Epoch 772/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4404 - accuracy: 0.7812 - val_loss: 0.5603 - val_accuracy: 0.7292\n",
      "Epoch 773/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4386 - accuracy: 0.7917 - val_loss: 0.5765 - val_accuracy: 0.7240\n",
      "Epoch 774/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4646 - accuracy: 0.7830 - val_loss: 0.5815 - val_accuracy: 0.7292\n",
      "Epoch 775/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.5545 - val_accuracy: 0.7292\n",
      "Epoch 776/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.5442 - val_accuracy: 0.7292\n",
      "Epoch 777/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4428 - accuracy: 0.7847 - val_loss: 0.5499 - val_accuracy: 0.7240\n",
      "Epoch 778/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5672 - val_accuracy: 0.7188\n",
      "Epoch 779/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4470 - accuracy: 0.7847 - val_loss: 0.5511 - val_accuracy: 0.7188\n",
      "Epoch 780/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5705 - val_accuracy: 0.7135\n",
      "Epoch 781/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.5446 - val_accuracy: 0.7135\n",
      "Epoch 782/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.5492 - val_accuracy: 0.7188\n",
      "Epoch 783/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5521 - val_accuracy: 0.7135\n",
      "Epoch 784/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.5870 - val_accuracy: 0.7292\n",
      "Epoch 785/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5840 - val_accuracy: 0.7240\n",
      "Epoch 786/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4420 - accuracy: 0.7795 - val_loss: 0.5485 - val_accuracy: 0.7135\n",
      "Epoch 787/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.5469 - val_accuracy: 0.7188\n",
      "Epoch 788/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4377 - accuracy: 0.8056 - val_loss: 0.5532 - val_accuracy: 0.7240\n",
      "Epoch 789/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4514 - accuracy: 0.7899 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 790/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 791/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4400 - accuracy: 0.7847 - val_loss: 0.5515 - val_accuracy: 0.7292\n",
      "Epoch 792/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4399 - accuracy: 0.8038 - val_loss: 0.5494 - val_accuracy: 0.7188\n",
      "Epoch 793/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4399 - accuracy: 0.7812 - val_loss: 0.5493 - val_accuracy: 0.7031\n",
      "Epoch 794/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.5510 - val_accuracy: 0.7083\n",
      "Epoch 795/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4458 - accuracy: 0.7847 - val_loss: 0.5575 - val_accuracy: 0.7083\n",
      "Epoch 796/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5512 - val_accuracy: 0.7292\n",
      "Epoch 797/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.5575 - val_accuracy: 0.7292\n",
      "Epoch 798/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.5501 - val_accuracy: 0.7188\n",
      "Epoch 799/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.5405 - val_accuracy: 0.7188\n",
      "Epoch 800/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
      "Epoch 801/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4393 - accuracy: 0.7865 - val_loss: 0.5666 - val_accuracy: 0.7188\n",
      "Epoch 802/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4405 - accuracy: 0.7778 - val_loss: 0.5391 - val_accuracy: 0.7344\n",
      "Epoch 803/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 804/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5454 - val_accuracy: 0.7135\n",
      "Epoch 805/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.5442 - val_accuracy: 0.7188\n",
      "Epoch 806/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5452 - val_accuracy: 0.7292\n",
      "Epoch 807/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.5578 - val_accuracy: 0.7188\n",
      "Epoch 808/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5570 - val_accuracy: 0.7083\n",
      "Epoch 809/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4385 - accuracy: 0.7865 - val_loss: 0.5533 - val_accuracy: 0.7135\n",
      "Epoch 810/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4403 - accuracy: 0.7951 - val_loss: 0.5592 - val_accuracy: 0.7135\n",
      "Epoch 811/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5626 - val_accuracy: 0.7240\n",
      "Epoch 812/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4390 - accuracy: 0.7865 - val_loss: 0.5475 - val_accuracy: 0.7083\n",
      "Epoch 813/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4349 - accuracy: 0.7812 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 814/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4432 - accuracy: 0.7917 - val_loss: 0.5569 - val_accuracy: 0.7188\n",
      "Epoch 815/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4502 - accuracy: 0.7760 - val_loss: 0.5684 - val_accuracy: 0.7344\n",
      "Epoch 816/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
      "Epoch 817/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5570 - val_accuracy: 0.7292\n",
      "Epoch 818/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.5751 - val_accuracy: 0.7188\n",
      "Epoch 819/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 820/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5573 - val_accuracy: 0.7292\n",
      "Epoch 821/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 822/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4367 - accuracy: 0.7865 - val_loss: 0.5639 - val_accuracy: 0.7031\n",
      "Epoch 823/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.5621 - val_accuracy: 0.7083\n",
      "Epoch 824/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4400 - accuracy: 0.7865 - val_loss: 0.5777 - val_accuracy: 0.7240\n",
      "Epoch 825/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4412 - accuracy: 0.7760 - val_loss: 0.5691 - val_accuracy: 0.7292\n",
      "Epoch 826/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4334 - accuracy: 0.8003 - val_loss: 0.5559 - val_accuracy: 0.7135\n",
      "Epoch 827/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
      "Epoch 828/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4364 - accuracy: 0.7969 - val_loss: 0.5758 - val_accuracy: 0.7240\n",
      "Epoch 829/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.5611 - val_accuracy: 0.7240\n",
      "Epoch 830/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4344 - accuracy: 0.7917 - val_loss: 0.5568 - val_accuracy: 0.7240\n",
      "Epoch 831/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4381 - accuracy: 0.7882 - val_loss: 0.5564 - val_accuracy: 0.7240\n",
      "Epoch 832/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5542 - val_accuracy: 0.7083\n",
      "Epoch 833/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.5463 - val_accuracy: 0.7188\n",
      "Epoch 834/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4408 - accuracy: 0.8021 - val_loss: 0.5530 - val_accuracy: 0.7083\n",
      "Epoch 835/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4399 - accuracy: 0.7986 - val_loss: 0.5627 - val_accuracy: 0.7240\n",
      "Epoch 836/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4362 - accuracy: 0.7969 - val_loss: 0.5671 - val_accuracy: 0.7135\n",
      "Epoch 837/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5675 - val_accuracy: 0.7135\n",
      "Epoch 838/1000\n",
      "576/576 [==============================] - 0s 74us/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
      "Epoch 839/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
      "Epoch 840/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4376 - accuracy: 0.7917 - val_loss: 0.5647 - val_accuracy: 0.7188\n",
      "Epoch 841/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4328 - accuracy: 0.7882 - val_loss: 0.5493 - val_accuracy: 0.7135\n",
      "Epoch 842/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5600 - val_accuracy: 0.7083\n",
      "Epoch 843/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4390 - accuracy: 0.7795 - val_loss: 0.5714 - val_accuracy: 0.7292\n",
      "Epoch 844/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4468 - accuracy: 0.7778 - val_loss: 0.5808 - val_accuracy: 0.7240\n",
      "Epoch 845/1000\n",
      "576/576 [==============================] - 0s 76us/step - loss: 0.4453 - accuracy: 0.7760 - val_loss: 0.5658 - val_accuracy: 0.7240\n",
      "Epoch 846/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
      "Epoch 847/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4332 - accuracy: 0.7899 - val_loss: 0.5599 - val_accuracy: 0.7083\n",
      "Epoch 848/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4456 - accuracy: 0.7899 - val_loss: 0.5600 - val_accuracy: 0.7135\n",
      "Epoch 849/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.5585 - val_accuracy: 0.7188\n",
      "Epoch 850/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.5675 - val_accuracy: 0.7240\n",
      "Epoch 851/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4347 - accuracy: 0.7882 - val_loss: 0.5767 - val_accuracy: 0.7135\n",
      "Epoch 852/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4498 - accuracy: 0.7795 - val_loss: 0.5611 - val_accuracy: 0.7083\n",
      "Epoch 853/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4430 - accuracy: 0.7934 - val_loss: 0.5607 - val_accuracy: 0.7240\n",
      "Epoch 854/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4520 - accuracy: 0.7951 - val_loss: 0.5533 - val_accuracy: 0.7083\n",
      "Epoch 855/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.5574 - val_accuracy: 0.7135\n",
      "Epoch 856/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5667 - val_accuracy: 0.7240\n",
      "Epoch 857/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5556 - val_accuracy: 0.7135\n",
      "Epoch 858/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4357 - accuracy: 0.7917 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
      "Epoch 859/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4353 - accuracy: 0.7882 - val_loss: 0.5753 - val_accuracy: 0.7188\n",
      "Epoch 860/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4340 - accuracy: 0.7934 - val_loss: 0.5672 - val_accuracy: 0.7292\n",
      "Epoch 861/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.5630 - val_accuracy: 0.7031\n",
      "Epoch 862/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4438 - accuracy: 0.7899 - val_loss: 0.5697 - val_accuracy: 0.7188\n",
      "Epoch 863/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5666 - val_accuracy: 0.7292\n",
      "Epoch 864/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.5670 - val_accuracy: 0.7240\n",
      "Epoch 865/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5577 - val_accuracy: 0.7083\n",
      "Epoch 866/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4396 - accuracy: 0.7830 - val_loss: 0.5719 - val_accuracy: 0.7292\n",
      "Epoch 867/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4375 - accuracy: 0.7969 - val_loss: 0.5629 - val_accuracy: 0.7083\n",
      "Epoch 868/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4567 - accuracy: 0.7726 - val_loss: 0.5858 - val_accuracy: 0.7188\n",
      "Epoch 869/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5762 - val_accuracy: 0.7083\n",
      "Epoch 870/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4477 - accuracy: 0.7951 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
      "Epoch 871/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.5562 - val_accuracy: 0.7135\n",
      "Epoch 872/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5472 - val_accuracy: 0.7188\n",
      "Epoch 873/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4472 - accuracy: 0.7865 - val_loss: 0.5745 - val_accuracy: 0.7188\n",
      "Epoch 874/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5552 - val_accuracy: 0.7135\n",
      "Epoch 875/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4331 - accuracy: 0.7899 - val_loss: 0.5594 - val_accuracy: 0.7240\n",
      "Epoch 876/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4365 - accuracy: 0.7917 - val_loss: 0.5709 - val_accuracy: 0.7240\n",
      "Epoch 877/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4333 - accuracy: 0.7899 - val_loss: 0.5548 - val_accuracy: 0.7135\n",
      "Epoch 878/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4344 - accuracy: 0.7899 - val_loss: 0.5571 - val_accuracy: 0.7240\n",
      "Epoch 879/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.5665 - val_accuracy: 0.7135\n",
      "Epoch 880/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4427 - accuracy: 0.7934 - val_loss: 0.5626 - val_accuracy: 0.7135\n",
      "Epoch 881/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4372 - accuracy: 0.7847 - val_loss: 0.5560 - val_accuracy: 0.7135\n",
      "Epoch 882/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5814 - val_accuracy: 0.7188\n",
      "Epoch 883/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4404 - accuracy: 0.8003 - val_loss: 0.5630 - val_accuracy: 0.7135\n",
      "Epoch 884/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
      "Epoch 885/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4359 - accuracy: 0.7830 - val_loss: 0.5675 - val_accuracy: 0.7292\n",
      "Epoch 886/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4399 - accuracy: 0.7882 - val_loss: 0.5776 - val_accuracy: 0.7188\n",
      "Epoch 887/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4269 - accuracy: 0.7934 - val_loss: 0.5609 - val_accuracy: 0.7135\n",
      "Epoch 888/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5685 - val_accuracy: 0.7292\n",
      "Epoch 889/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4473 - accuracy: 0.7969 - val_loss: 0.5524 - val_accuracy: 0.7188\n",
      "Epoch 890/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4337 - accuracy: 0.7830 - val_loss: 0.5583 - val_accuracy: 0.7083\n",
      "Epoch 891/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4419 - accuracy: 0.7951 - val_loss: 0.5849 - val_accuracy: 0.7240\n",
      "Epoch 892/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4357 - accuracy: 0.7934 - val_loss: 0.5522 - val_accuracy: 0.7188\n",
      "Epoch 893/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4375 - accuracy: 0.7899 - val_loss: 0.5663 - val_accuracy: 0.7031\n",
      "Epoch 894/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5831 - val_accuracy: 0.7240\n",
      "Epoch 895/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4354 - accuracy: 0.7882 - val_loss: 0.5789 - val_accuracy: 0.7188\n",
      "Epoch 896/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.5654 - val_accuracy: 0.7135\n",
      "Epoch 897/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.5792 - val_accuracy: 0.7188\n",
      "Epoch 898/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4366 - accuracy: 0.7917 - val_loss: 0.5653 - val_accuracy: 0.7188\n",
      "Epoch 899/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4435 - accuracy: 0.7847 - val_loss: 0.5643 - val_accuracy: 0.7240\n",
      "Epoch 900/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.5719 - val_accuracy: 0.7292\n",
      "Epoch 901/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4398 - accuracy: 0.7865 - val_loss: 0.5721 - val_accuracy: 0.7188\n",
      "Epoch 902/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4426 - accuracy: 0.7934 - val_loss: 0.5651 - val_accuracy: 0.7135\n",
      "Epoch 903/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4379 - accuracy: 0.7882 - val_loss: 0.5568 - val_accuracy: 0.7188\n",
      "Epoch 904/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4364 - accuracy: 0.7865 - val_loss: 0.5845 - val_accuracy: 0.7240\n",
      "Epoch 905/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.5713 - val_accuracy: 0.7083\n",
      "Epoch 906/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4349 - accuracy: 0.7882 - val_loss: 0.5651 - val_accuracy: 0.7135\n",
      "Epoch 907/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4382 - accuracy: 0.7882 - val_loss: 0.5619 - val_accuracy: 0.7240\n",
      "Epoch 908/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4387 - accuracy: 0.7865 - val_loss: 0.5688 - val_accuracy: 0.7292\n",
      "Epoch 909/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4352 - accuracy: 0.7882 - val_loss: 0.5757 - val_accuracy: 0.7135\n",
      "Epoch 910/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5760 - val_accuracy: 0.7188\n",
      "Epoch 911/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4365 - accuracy: 0.7986 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
      "Epoch 912/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5666 - val_accuracy: 0.7135\n",
      "Epoch 913/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5924 - val_accuracy: 0.7240\n",
      "Epoch 914/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4453 - accuracy: 0.7986 - val_loss: 0.5691 - val_accuracy: 0.7083\n",
      "Epoch 915/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.5868 - val_accuracy: 0.7292\n",
      "Epoch 916/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5582 - val_accuracy: 0.7083\n",
      "Epoch 917/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5741 - val_accuracy: 0.7135\n",
      "Epoch 918/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4361 - accuracy: 0.7969 - val_loss: 0.5705 - val_accuracy: 0.7135\n",
      "Epoch 919/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4373 - accuracy: 0.7917 - val_loss: 0.5713 - val_accuracy: 0.7135\n",
      "Epoch 920/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4409 - accuracy: 0.7812 - val_loss: 0.5632 - val_accuracy: 0.7188\n",
      "Epoch 921/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4423 - accuracy: 0.7726 - val_loss: 0.5623 - val_accuracy: 0.7083\n",
      "Epoch 922/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5572 - val_accuracy: 0.7188\n",
      "Epoch 923/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4417 - accuracy: 0.7969 - val_loss: 0.5806 - val_accuracy: 0.7188\n",
      "Epoch 924/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4327 - accuracy: 0.7882 - val_loss: 0.5655 - val_accuracy: 0.7188\n",
      "Epoch 925/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4461 - accuracy: 0.7847 - val_loss: 0.5678 - val_accuracy: 0.7188\n",
      "Epoch 926/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.5747 - val_accuracy: 0.7083\n",
      "Epoch 927/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4352 - accuracy: 0.7934 - val_loss: 0.5777 - val_accuracy: 0.7240\n",
      "Epoch 928/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4549 - accuracy: 0.7795 - val_loss: 0.5619 - val_accuracy: 0.7135\n",
      "Epoch 929/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4494 - accuracy: 0.7708 - val_loss: 0.5951 - val_accuracy: 0.7240\n",
      "Epoch 930/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4409 - accuracy: 0.7899 - val_loss: 0.5662 - val_accuracy: 0.7240\n",
      "Epoch 931/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4396 - accuracy: 0.8056 - val_loss: 0.5811 - val_accuracy: 0.7188\n",
      "Epoch 932/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4423 - accuracy: 0.7760 - val_loss: 0.5530 - val_accuracy: 0.7188\n",
      "Epoch 933/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4368 - accuracy: 0.7830 - val_loss: 0.5636 - val_accuracy: 0.7031\n",
      "Epoch 934/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5773 - val_accuracy: 0.7292\n",
      "Epoch 935/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.5635 - val_accuracy: 0.7083\n",
      "Epoch 936/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.5646 - val_accuracy: 0.7135\n",
      "Epoch 937/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4394 - accuracy: 0.7795 - val_loss: 0.5633 - val_accuracy: 0.7240\n",
      "Epoch 938/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4430 - accuracy: 0.7847 - val_loss: 0.5648 - val_accuracy: 0.7135\n",
      "Epoch 939/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5578 - val_accuracy: 0.7083\n",
      "Epoch 940/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5808 - val_accuracy: 0.7240\n",
      "Epoch 941/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4515 - accuracy: 0.7708 - val_loss: 0.5678 - val_accuracy: 0.7083\n",
      "Epoch 942/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4412 - accuracy: 0.7847 - val_loss: 0.5911 - val_accuracy: 0.7188\n",
      "Epoch 943/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4342 - accuracy: 0.8003 - val_loss: 0.5981 - val_accuracy: 0.7292\n",
      "Epoch 944/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.5619 - val_accuracy: 0.7083\n",
      "Epoch 945/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4478 - accuracy: 0.7795 - val_loss: 0.5643 - val_accuracy: 0.7240\n",
      "Epoch 946/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4342 - accuracy: 0.7899 - val_loss: 0.5601 - val_accuracy: 0.7188\n",
      "Epoch 947/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4340 - accuracy: 0.7830 - val_loss: 0.5819 - val_accuracy: 0.7188\n",
      "Epoch 948/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4365 - accuracy: 0.7899 - val_loss: 0.5781 - val_accuracy: 0.7292\n",
      "Epoch 949/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4421 - accuracy: 0.7847 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 950/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4404 - accuracy: 0.7795 - val_loss: 0.5702 - val_accuracy: 0.7083\n",
      "Epoch 951/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4387 - accuracy: 0.7917 - val_loss: 0.5581 - val_accuracy: 0.7083\n",
      "Epoch 952/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4383 - accuracy: 0.7882 - val_loss: 0.5680 - val_accuracy: 0.7135\n",
      "Epoch 953/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.5578 - val_accuracy: 0.7135\n",
      "Epoch 954/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4310 - accuracy: 0.7917 - val_loss: 0.5566 - val_accuracy: 0.7083\n",
      "Epoch 955/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.5609 - val_accuracy: 0.7083\n",
      "Epoch 956/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4461 - accuracy: 0.7865 - val_loss: 0.5633 - val_accuracy: 0.7135\n",
      "Epoch 957/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.5648 - val_accuracy: 0.7083\n",
      "Epoch 958/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5647 - val_accuracy: 0.7135\n",
      "Epoch 959/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5740 - val_accuracy: 0.7083\n",
      "Epoch 960/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4384 - accuracy: 0.7847 - val_loss: 0.5841 - val_accuracy: 0.7396\n",
      "Epoch 961/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4293 - accuracy: 0.8073 - val_loss: 0.5862 - val_accuracy: 0.7188\n",
      "Epoch 962/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.5749 - val_accuracy: 0.7188\n",
      "Epoch 963/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4418 - accuracy: 0.7865 - val_loss: 0.5722 - val_accuracy: 0.7083\n",
      "Epoch 964/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4438 - accuracy: 0.7830 - val_loss: 0.5773 - val_accuracy: 0.7031\n",
      "Epoch 965/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5620 - val_accuracy: 0.7083\n",
      "Epoch 966/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.5818 - val_accuracy: 0.7188\n",
      "Epoch 967/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5697 - val_accuracy: 0.7083\n",
      "Epoch 968/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4437 - accuracy: 0.7882 - val_loss: 0.5778 - val_accuracy: 0.7240\n",
      "Epoch 969/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.5819 - val_accuracy: 0.7188\n",
      "Epoch 970/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4440 - accuracy: 0.7847 - val_loss: 0.5565 - val_accuracy: 0.7031\n",
      "Epoch 971/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.5660 - val_accuracy: 0.7188\n",
      "Epoch 972/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.5565 - val_accuracy: 0.7083\n",
      "Epoch 973/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4346 - accuracy: 0.7865 - val_loss: 0.5553 - val_accuracy: 0.7083\n",
      "Epoch 974/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4398 - accuracy: 0.7847 - val_loss: 0.5626 - val_accuracy: 0.7188\n",
      "Epoch 975/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5773 - val_accuracy: 0.7083\n",
      "Epoch 976/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5608 - val_accuracy: 0.7135\n",
      "Epoch 977/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4451 - accuracy: 0.7899 - val_loss: 0.5978 - val_accuracy: 0.7240\n",
      "Epoch 978/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4498 - accuracy: 0.7899 - val_loss: 0.5697 - val_accuracy: 0.7240\n",
      "Epoch 979/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4390 - accuracy: 0.7743 - val_loss: 0.5559 - val_accuracy: 0.7188\n",
      "Epoch 980/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4444 - accuracy: 0.7934 - val_loss: 0.5589 - val_accuracy: 0.7083\n",
      "Epoch 981/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4361 - accuracy: 0.7865 - val_loss: 0.5711 - val_accuracy: 0.7188\n",
      "Epoch 982/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.5693 - val_accuracy: 0.7135\n",
      "Epoch 983/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.5743 - val_accuracy: 0.7188\n",
      "Epoch 984/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.5769 - val_accuracy: 0.7292\n",
      "Epoch 985/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
      "Epoch 986/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5700 - val_accuracy: 0.7135\n",
      "Epoch 987/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4350 - accuracy: 0.7934 - val_loss: 0.5713 - val_accuracy: 0.7240\n",
      "Epoch 988/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4324 - accuracy: 0.8003 - val_loss: 0.5654 - val_accuracy: 0.7135\n",
      "Epoch 989/1000\n",
      "576/576 [==============================] - 0s 80us/step - loss: 0.4377 - accuracy: 0.7882 - val_loss: 0.5782 - val_accuracy: 0.7292\n",
      "Epoch 990/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.5864 - val_accuracy: 0.7240\n",
      "Epoch 991/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4513 - accuracy: 0.7986 - val_loss: 0.5637 - val_accuracy: 0.7083\n",
      "Epoch 992/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4387 - accuracy: 0.7882 - val_loss: 0.5655 - val_accuracy: 0.7031\n",
      "Epoch 993/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4407 - accuracy: 0.7986 - val_loss: 0.5775 - val_accuracy: 0.7292\n",
      "Epoch 994/1000\n",
      "576/576 [==============================] - 0s 78us/step - loss: 0.4358 - accuracy: 0.7917 - val_loss: 0.5745 - val_accuracy: 0.7292\n",
      "Epoch 995/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4538 - accuracy: 0.7812 - val_loss: 0.5730 - val_accuracy: 0.7135\n",
      "Epoch 996/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.5748 - val_accuracy: 0.7240\n",
      "Epoch 997/1000\n",
      "576/576 [==============================] - 0s 75us/step - loss: 0.4393 - accuracy: 0.7760 - val_loss: 0.5731 - val_accuracy: 0.7292\n",
      "Epoch 998/1000\n",
      "576/576 [==============================] - 0s 77us/step - loss: 0.4364 - accuracy: 0.7917 - val_loss: 0.5742 - val_accuracy: 0.7292\n",
      "Epoch 999/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4391 - accuracy: 0.7865 - val_loss: 0.5579 - val_accuracy: 0.7031\n",
      "Epoch 1000/1000\n",
      "576/576 [==============================] - 0s 79us/step - loss: 0.4304 - accuracy: 0.7899 - val_loss: 0.5812 - val_accuracy: 0.7240\n"
     ]
    }
   ],
   "source": [
    "NB_EPOCHS = 1000  # num of epochs to test for\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "## Create our model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer: input_dim=8, 12 nodes, RELU\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "# Add dropout\n",
    "#model.add(Dropout(0.1))\n",
    "# 2nd layer: 8 nodes, RELU\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "# Add Droput\n",
    "#model.add(Dropout(0.1))\n",
    "# output layer: dim=1, activation sigmoid\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid' ))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',   # since we are predicting 0/1\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "'''#checkpoint: store the best model\n",
    "ckpt_model = 'pima-weights.best.hdf5'\n",
    "checkpoint = ModelCheckpoint(ckpt_model, \n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "callbacks_list = [checkpoint]'''\n",
    "\n",
    "print('Starting training...')\n",
    "# train the model, store the results for plotting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    nb_epoch=NB_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    #callbacks=callbacks_list,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Losss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 72.40%\n"
     ]
    }
   ],
   "source": [
    "# print final accuracy\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Few Take aways\n",
    "- Model preformace is terible if you introduce a dropout\n",
    "- Model as it stands in not great as it is not generalizing well on validation data\n",
    "- Try complex model, increase number of dense layer nodes in each layer\n",
    "- Try with/ without call back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_x_train = scaler.fit_transform(X_train)\n",
    "scaled_x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288 samples, validate on 288 samples\n",
      "Epoch 1/400\n",
      "288/288 [==============================] - 0s 910us/step - loss: 0.6716 - accuracy: 0.6215 - val_loss: 0.6448 - val_accuracy: 0.6562\n",
      "Epoch 2/400\n",
      "288/288 [==============================] - 0s 78us/step - loss: 0.6617 - accuracy: 0.6285 - val_loss: 0.6387 - val_accuracy: 0.6562\n",
      "Epoch 3/400\n",
      "288/288 [==============================] - 0s 77us/step - loss: 0.6497 - accuracy: 0.6285 - val_loss: 0.6310 - val_accuracy: 0.6562\n",
      "Epoch 4/400\n",
      "288/288 [==============================] - 0s 75us/step - loss: 0.6343 - accuracy: 0.6354 - val_loss: 0.6124 - val_accuracy: 0.6736\n",
      "Epoch 5/400\n",
      "288/288 [==============================] - 0s 80us/step - loss: 0.6126 - accuracy: 0.6597 - val_loss: 0.5880 - val_accuracy: 0.6910\n",
      "Epoch 6/400\n",
      "288/288 [==============================] - 0s 77us/step - loss: 0.5953 - accuracy: 0.6944 - val_loss: 0.5659 - val_accuracy: 0.7292\n",
      "Epoch 7/400\n",
      "288/288 [==============================] - 0s 76us/step - loss: 0.5613 - accuracy: 0.7118 - val_loss: 0.5478 - val_accuracy: 0.7431\n",
      "Epoch 8/400\n",
      "288/288 [==============================] - 0s 77us/step - loss: 0.5440 - accuracy: 0.7257 - val_loss: 0.5347 - val_accuracy: 0.7431\n",
      "Epoch 9/400\n",
      "288/288 [==============================] - 0s 76us/step - loss: 0.5296 - accuracy: 0.7535 - val_loss: 0.5166 - val_accuracy: 0.7465\n",
      "Epoch 10/400\n",
      "288/288 [==============================] - 0s 78us/step - loss: 0.5362 - accuracy: 0.7257 - val_loss: 0.5288 - val_accuracy: 0.7431\n",
      "Epoch 11/400\n",
      "288/288 [==============================] - 0s 77us/step - loss: 0.5064 - accuracy: 0.7535 - val_loss: 0.5151 - val_accuracy: 0.7431\n",
      "Epoch 12/400\n",
      "288/288 [==============================] - 0s 71us/step - loss: 0.4873 - accuracy: 0.7847 - val_loss: 0.5104 - val_accuracy: 0.7396\n",
      "Epoch 13/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.5074 - val_accuracy: 0.7431\n",
      "Epoch 14/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4816 - accuracy: 0.7674 - val_loss: 0.5107 - val_accuracy: 0.7569\n",
      "Epoch 15/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4888 - accuracy: 0.7674 - val_loss: 0.5070 - val_accuracy: 0.7431\n",
      "Epoch 16/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4988 - accuracy: 0.7535 - val_loss: 0.5037 - val_accuracy: 0.7500\n",
      "Epoch 17/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4820 - accuracy: 0.7812 - val_loss: 0.5412 - val_accuracy: 0.7222\n",
      "Epoch 18/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.5083 - accuracy: 0.7431 - val_loss: 0.5009 - val_accuracy: 0.7500\n",
      "Epoch 19/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4937 - accuracy: 0.7708 - val_loss: 0.5012 - val_accuracy: 0.7465\n",
      "Epoch 20/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4866 - accuracy: 0.7535 - val_loss: 0.5000 - val_accuracy: 0.7500\n",
      "Epoch 21/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4789 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.7465\n",
      "Epoch 22/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4792 - accuracy: 0.7639 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 23/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.4964 - val_accuracy: 0.7569\n",
      "Epoch 24/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4806 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7500\n",
      "Epoch 25/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4789 - accuracy: 0.7882 - val_loss: 0.5011 - val_accuracy: 0.7396\n",
      "Epoch 26/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7535\n",
      "Epoch 27/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4903 - accuracy: 0.7604 - val_loss: 0.5187 - val_accuracy: 0.7569\n",
      "Epoch 28/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4834 - accuracy: 0.7778 - val_loss: 0.5077 - val_accuracy: 0.7431\n",
      "Epoch 29/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4755 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7569\n",
      "Epoch 30/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4860 - accuracy: 0.7604 - val_loss: 0.5009 - val_accuracy: 0.7396\n",
      "Epoch 31/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4844 - accuracy: 0.7569 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
      "Epoch 32/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4751 - accuracy: 0.7882 - val_loss: 0.5018 - val_accuracy: 0.7431\n",
      "Epoch 33/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4766 - accuracy: 0.7778 - val_loss: 0.4966 - val_accuracy: 0.7396\n",
      "Epoch 34/400\n",
      "288/288 [==============================] - 0s 64us/step - loss: 0.4727 - accuracy: 0.7951 - val_loss: 0.4959 - val_accuracy: 0.7535\n",
      "Epoch 35/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4917 - accuracy: 0.7674 - val_loss: 0.4988 - val_accuracy: 0.7500\n",
      "Epoch 36/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4709 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 37/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4715 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7431\n",
      "Epoch 38/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7569\n",
      "Epoch 39/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4668 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 40/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4769 - accuracy: 0.7812 - val_loss: 0.4946 - val_accuracy: 0.7535\n",
      "Epoch 41/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.4921 - val_accuracy: 0.7639\n",
      "Epoch 42/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4527 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7674\n",
      "Epoch 43/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4825 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 44/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7639\n",
      "Epoch 45/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7639\n",
      "Epoch 46/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7569\n",
      "Epoch 47/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4544 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7639\n",
      "Epoch 48/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7639\n",
      "Epoch 49/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4719 - accuracy: 0.7882 - val_loss: 0.4913 - val_accuracy: 0.7674\n",
      "Epoch 50/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4758 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7465\n",
      "Epoch 51/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.4958 - val_accuracy: 0.7465\n",
      "Epoch 52/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7639\n",
      "Epoch 53/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4655 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 54/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4617 - accuracy: 0.7917 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 55/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4700 - accuracy: 0.7882 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 56/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4867 - accuracy: 0.7708 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 57/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7639\n",
      "Epoch 58/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4877 - accuracy: 0.7535 - val_loss: 0.4880 - val_accuracy: 0.7674\n",
      "Epoch 59/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4638 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7535\n",
      "Epoch 60/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4739 - accuracy: 0.7674 - val_loss: 0.4900 - val_accuracy: 0.7569\n",
      "Epoch 61/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7535\n",
      "Epoch 62/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4606 - accuracy: 0.7986 - val_loss: 0.4889 - val_accuracy: 0.7639\n",
      "Epoch 63/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4655 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7674\n",
      "Epoch 64/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4476 - accuracy: 0.7917 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 65/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.4897 - val_accuracy: 0.7639\n",
      "Epoch 66/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4617 - accuracy: 0.7882 - val_loss: 0.4907 - val_accuracy: 0.7569\n",
      "Epoch 67/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4548 - accuracy: 0.7917 - val_loss: 0.4888 - val_accuracy: 0.7639\n",
      "Epoch 68/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 69/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4785 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7569\n",
      "Epoch 70/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4639 - accuracy: 0.8021 - val_loss: 0.4886 - val_accuracy: 0.7569\n",
      "Epoch 71/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4634 - accuracy: 0.7986 - val_loss: 0.4900 - val_accuracy: 0.7569\n",
      "Epoch 72/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4897 - val_accuracy: 0.7569\n",
      "Epoch 73/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4897 - val_accuracy: 0.7569\n",
      "Epoch 74/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7708\n",
      "Epoch 75/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.4868 - val_accuracy: 0.7674\n",
      "Epoch 76/400\n",
      "288/288 [==============================] - 0s 64us/step - loss: 0.4620 - accuracy: 0.7917 - val_loss: 0.4911 - val_accuracy: 0.7500\n",
      "Epoch 77/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.4900 - val_accuracy: 0.7569\n",
      "Epoch 78/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 79/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7639\n",
      "Epoch 80/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4875 - val_accuracy: 0.7743\n",
      "Epoch 81/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7569\n",
      "Epoch 82/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7708\n",
      "Epoch 83/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4603 - accuracy: 0.7951 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 84/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7604\n",
      "Epoch 85/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7674\n",
      "Epoch 86/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7604\n",
      "Epoch 87/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7743\n",
      "Epoch 88/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 89/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4895 - val_accuracy: 0.7604\n",
      "Epoch 90/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4727 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7674\n",
      "Epoch 91/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 92/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.4894 - val_accuracy: 0.7674\n",
      "Epoch 93/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
      "Epoch 94/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4581 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
      "Epoch 95/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4528 - accuracy: 0.7951 - val_loss: 0.4891 - val_accuracy: 0.7639\n",
      "Epoch 96/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
      "Epoch 97/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4643 - accuracy: 0.7951 - val_loss: 0.4897 - val_accuracy: 0.7604\n",
      "Epoch 98/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4701 - accuracy: 0.7812 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 99/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4754 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7674\n",
      "Epoch 100/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
      "Epoch 101/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4545 - accuracy: 0.8056 - val_loss: 0.4881 - val_accuracy: 0.7639\n",
      "Epoch 102/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4621 - accuracy: 0.7917 - val_loss: 0.4923 - val_accuracy: 0.7535\n",
      "Epoch 103/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.4893 - val_accuracy: 0.7639\n",
      "Epoch 104/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4672 - accuracy: 0.7882 - val_loss: 0.4884 - val_accuracy: 0.7674\n",
      "Epoch 105/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7569\n",
      "Epoch 106/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4610 - accuracy: 0.7917 - val_loss: 0.4938 - val_accuracy: 0.7535\n",
      "Epoch 107/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7639\n",
      "Epoch 108/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4804 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7639\n",
      "Epoch 109/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4586 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7535\n",
      "Epoch 110/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7604\n",
      "Epoch 111/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4537 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7674\n",
      "Epoch 112/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4555 - accuracy: 0.7847 - val_loss: 0.4878 - val_accuracy: 0.7674\n",
      "Epoch 113/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 114/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7639\n",
      "Epoch 115/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4692 - accuracy: 0.7812 - val_loss: 0.4861 - val_accuracy: 0.7639\n",
      "Epoch 116/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4581 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7674\n",
      "Epoch 117/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.4857 - val_accuracy: 0.7674\n",
      "Epoch 118/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4852 - val_accuracy: 0.7604\n",
      "Epoch 119/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4645 - accuracy: 0.8056 - val_loss: 0.4867 - val_accuracy: 0.7639\n",
      "Epoch 120/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7535\n",
      "Epoch 121/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4867 - val_accuracy: 0.7674\n",
      "Epoch 122/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4609 - accuracy: 0.7917 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 123/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4772 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7743\n",
      "Epoch 124/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7604\n",
      "Epoch 125/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4857 - val_accuracy: 0.7569\n",
      "Epoch 126/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4685 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7743\n",
      "Epoch 127/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4483 - accuracy: 0.7951 - val_loss: 0.4865 - val_accuracy: 0.7674\n",
      "Epoch 128/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 129/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4571 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7604\n",
      "Epoch 130/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4586 - accuracy: 0.7951 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 131/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4619 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 132/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4600 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7639\n",
      "Epoch 133/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4528 - accuracy: 0.7917 - val_loss: 0.4857 - val_accuracy: 0.7569\n",
      "Epoch 134/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4593 - accuracy: 0.7882 - val_loss: 0.4862 - val_accuracy: 0.7639\n",
      "Epoch 135/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.4854 - val_accuracy: 0.7569\n",
      "Epoch 136/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4463 - accuracy: 0.7951 - val_loss: 0.4852 - val_accuracy: 0.7535\n",
      "Epoch 137/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4681 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7569\n",
      "Epoch 138/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.4854 - val_accuracy: 0.7569\n",
      "Epoch 139/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7674\n",
      "Epoch 140/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4458 - accuracy: 0.7986 - val_loss: 0.4861 - val_accuracy: 0.7639\n",
      "Epoch 141/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4500 - accuracy: 0.8021 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 142/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4552 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7569\n",
      "Epoch 143/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4556 - accuracy: 0.8021 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 144/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4871 - val_accuracy: 0.7535\n",
      "Epoch 145/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4543 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7535\n",
      "Epoch 146/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4608 - accuracy: 0.7917 - val_loss: 0.4862 - val_accuracy: 0.7639\n",
      "Epoch 147/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4539 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7569\n",
      "Epoch 148/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4479 - accuracy: 0.7882 - val_loss: 0.4864 - val_accuracy: 0.7639\n",
      "Epoch 149/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4619 - accuracy: 0.7917 - val_loss: 0.4863 - val_accuracy: 0.7535\n",
      "Epoch 150/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4637 - accuracy: 0.7951 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 151/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7569\n",
      "Epoch 152/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4712 - accuracy: 0.7812 - val_loss: 0.4854 - val_accuracy: 0.7569\n",
      "Epoch 153/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7535\n",
      "Epoch 154/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4594 - accuracy: 0.7882 - val_loss: 0.4909 - val_accuracy: 0.7569\n",
      "Epoch 155/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4552 - accuracy: 0.7917 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 156/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4608 - accuracy: 0.7812 - val_loss: 0.4852 - val_accuracy: 0.7535\n",
      "Epoch 157/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4850 - val_accuracy: 0.7535\n",
      "Epoch 158/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4568 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7604\n",
      "Epoch 159/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4539 - accuracy: 0.7917 - val_loss: 0.4852 - val_accuracy: 0.7569\n",
      "Epoch 160/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4595 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7535\n",
      "Epoch 161/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 162/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4524 - accuracy: 0.7917 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 163/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4554 - accuracy: 0.7917 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 164/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4710 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7569\n",
      "Epoch 165/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4599 - accuracy: 0.7812 - val_loss: 0.4907 - val_accuracy: 0.7535\n",
      "Epoch 166/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4580 - accuracy: 0.7882 - val_loss: 0.4862 - val_accuracy: 0.7569\n",
      "Epoch 167/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4522 - accuracy: 0.7917 - val_loss: 0.4852 - val_accuracy: 0.7569\n",
      "Epoch 168/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4590 - accuracy: 0.7917 - val_loss: 0.4857 - val_accuracy: 0.7569\n",
      "Epoch 169/400\n",
      "288/288 [==============================] - 0s 71us/step - loss: 0.4518 - accuracy: 0.7917 - val_loss: 0.4866 - val_accuracy: 0.7535\n",
      "Epoch 170/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4544 - accuracy: 0.7917 - val_loss: 0.4856 - val_accuracy: 0.7535\n",
      "Epoch 171/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4596 - accuracy: 0.7882 - val_loss: 0.4867 - val_accuracy: 0.7569\n",
      "Epoch 172/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4427 - accuracy: 0.7951 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 173/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4633 - accuracy: 0.7917 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 174/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4484 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7535\n",
      "Epoch 175/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.4868 - val_accuracy: 0.7569\n",
      "Epoch 176/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4596 - accuracy: 0.7917 - val_loss: 0.4859 - val_accuracy: 0.7535\n",
      "Epoch 177/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4469 - accuracy: 0.8021 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 178/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4631 - accuracy: 0.7917 - val_loss: 0.4874 - val_accuracy: 0.7569\n",
      "Epoch 179/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 180/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.4862 - val_accuracy: 0.7535\n",
      "Epoch 181/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4566 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7535\n",
      "Epoch 182/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4506 - accuracy: 0.8056 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 183/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4573 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7569\n",
      "Epoch 184/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4490 - accuracy: 0.7917 - val_loss: 0.4867 - val_accuracy: 0.7535\n",
      "Epoch 185/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4564 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7569\n",
      "Epoch 186/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4605 - accuracy: 0.7917 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 187/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4524 - accuracy: 0.7986 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 188/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4480 - accuracy: 0.7986 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 189/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4629 - accuracy: 0.7743 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 190/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 191/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 192/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 193/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4857 - val_accuracy: 0.7500\n",
      "Epoch 194/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 195/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.4863 - val_accuracy: 0.7535\n",
      "Epoch 196/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4527 - accuracy: 0.7743 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 197/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4618 - accuracy: 0.7917 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 198/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4599 - accuracy: 0.7917 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 199/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4530 - accuracy: 0.7951 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 200/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 201/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4619 - accuracy: 0.7917 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 202/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 203/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4550 - accuracy: 0.7917 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
      "Epoch 204/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7500\n",
      "Epoch 205/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 206/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4543 - accuracy: 0.7951 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 207/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4412 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7500\n",
      "Epoch 208/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4653 - accuracy: 0.7708 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 209/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4481 - accuracy: 0.7986 - val_loss: 0.4851 - val_accuracy: 0.7500\n",
      "Epoch 210/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4548 - accuracy: 0.7847 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 211/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4558 - accuracy: 0.7778 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 212/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4517 - accuracy: 0.7847 - val_loss: 0.4853 - val_accuracy: 0.7500\n",
      "Epoch 213/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4541 - accuracy: 0.7951 - val_loss: 0.4851 - val_accuracy: 0.7465\n",
      "Epoch 214/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4621 - accuracy: 0.7743 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
      "Epoch 215/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4480 - accuracy: 0.7847 - val_loss: 0.4849 - val_accuracy: 0.7465\n",
      "Epoch 216/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4493 - accuracy: 0.7986 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
      "Epoch 217/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4517 - accuracy: 0.7951 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 218/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4519 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7500\n",
      "Epoch 219/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4512 - accuracy: 0.8021 - val_loss: 0.4861 - val_accuracy: 0.7465\n",
      "Epoch 220/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4526 - accuracy: 0.7917 - val_loss: 0.4870 - val_accuracy: 0.7535\n",
      "Epoch 221/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4852 - val_accuracy: 0.7431\n",
      "Epoch 222/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.4848 - val_accuracy: 0.7465\n",
      "Epoch 223/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4450 - accuracy: 0.7847 - val_loss: 0.4853 - val_accuracy: 0.7465\n",
      "Epoch 224/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4527 - accuracy: 0.7882 - val_loss: 0.4852 - val_accuracy: 0.7465\n",
      "Epoch 225/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4512 - accuracy: 0.7812 - val_loss: 0.4851 - val_accuracy: 0.7465\n",
      "Epoch 226/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 227/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 228/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.4852 - val_accuracy: 0.7396\n",
      "Epoch 229/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4858 - val_accuracy: 0.7500\n",
      "Epoch 230/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4493 - accuracy: 0.7917 - val_loss: 0.4852 - val_accuracy: 0.7465\n",
      "Epoch 231/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4496 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 232/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 233/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4399 - accuracy: 0.7917 - val_loss: 0.4867 - val_accuracy: 0.7465\n",
      "Epoch 234/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4854 - val_accuracy: 0.7500\n",
      "Epoch 235/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.4857 - val_accuracy: 0.7465\n",
      "Epoch 236/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4540 - accuracy: 0.7812 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 237/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4521 - accuracy: 0.7951 - val_loss: 0.4866 - val_accuracy: 0.7465\n",
      "Epoch 238/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4534 - accuracy: 0.7917 - val_loss: 0.4863 - val_accuracy: 0.7500\n",
      "Epoch 239/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4552 - accuracy: 0.7812 - val_loss: 0.4869 - val_accuracy: 0.7465\n",
      "Epoch 240/400\n",
      "288/288 [==============================] - 0s 73us/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.4864 - val_accuracy: 0.7500\n",
      "Epoch 241/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4433 - accuracy: 0.7951 - val_loss: 0.4866 - val_accuracy: 0.7465\n",
      "Epoch 242/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4528 - accuracy: 0.7917 - val_loss: 0.4856 - val_accuracy: 0.7431\n",
      "Epoch 243/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4520 - accuracy: 0.7986 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 244/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 245/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4456 - accuracy: 0.7986 - val_loss: 0.4856 - val_accuracy: 0.7431\n",
      "Epoch 246/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4616 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 247/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4543 - accuracy: 0.7917 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 248/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4528 - accuracy: 0.7917 - val_loss: 0.4873 - val_accuracy: 0.7465\n",
      "Epoch 249/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.4858 - val_accuracy: 0.7465\n",
      "Epoch 250/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4589 - accuracy: 0.7847 - val_loss: 0.4853 - val_accuracy: 0.7465\n",
      "Epoch 251/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.4862 - val_accuracy: 0.7500\n",
      "Epoch 252/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4854 - val_accuracy: 0.7465\n",
      "Epoch 253/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.4855 - val_accuracy: 0.7431\n",
      "Epoch 254/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4543 - accuracy: 0.7951 - val_loss: 0.4857 - val_accuracy: 0.7431\n",
      "Epoch 255/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 256/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4478 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 257/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7396\n",
      "Epoch 258/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 259/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4517 - accuracy: 0.7882 - val_loss: 0.4860 - val_accuracy: 0.7431\n",
      "Epoch 260/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7465\n",
      "Epoch 261/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.4861 - val_accuracy: 0.7431\n",
      "Epoch 262/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4478 - accuracy: 0.8021 - val_loss: 0.4866 - val_accuracy: 0.7500\n",
      "Epoch 263/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7465\n",
      "Epoch 264/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.4862 - val_accuracy: 0.7431\n",
      "Epoch 265/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4612 - accuracy: 0.7847 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 266/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4577 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 267/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4458 - accuracy: 0.7951 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 268/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.4868 - val_accuracy: 0.7465\n",
      "Epoch 269/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 270/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.4864 - val_accuracy: 0.7465\n",
      "Epoch 271/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.4862 - val_accuracy: 0.7465\n",
      "Epoch 272/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4858 - val_accuracy: 0.7465\n",
      "Epoch 273/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4867 - val_accuracy: 0.7500\n",
      "Epoch 274/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4590 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 275/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.4859 - val_accuracy: 0.7431\n",
      "Epoch 276/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4543 - accuracy: 0.8021 - val_loss: 0.4868 - val_accuracy: 0.7500\n",
      "Epoch 277/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4577 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7500\n",
      "Epoch 278/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7465\n",
      "Epoch 279/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7465\n",
      "Epoch 280/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 281/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4419 - accuracy: 0.7917 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 282/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4496 - accuracy: 0.7986 - val_loss: 0.4861 - val_accuracy: 0.7396\n",
      "Epoch 283/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4569 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7535\n",
      "Epoch 284/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4560 - accuracy: 0.7847 - val_loss: 0.4869 - val_accuracy: 0.7500\n",
      "Epoch 285/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4680 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7431\n",
      "Epoch 286/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 287/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4485 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 288/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7465\n",
      "Epoch 289/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.4863 - val_accuracy: 0.7431\n",
      "Epoch 290/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 291/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7535\n",
      "Epoch 292/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.4865 - val_accuracy: 0.7431\n",
      "Epoch 293/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7465\n",
      "Epoch 294/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4483 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
      "Epoch 295/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4449 - accuracy: 0.7986 - val_loss: 0.4868 - val_accuracy: 0.7431\n",
      "Epoch 296/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4436 - accuracy: 0.7986 - val_loss: 0.4871 - val_accuracy: 0.7465\n",
      "Epoch 297/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4558 - accuracy: 0.7812 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 298/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4480 - accuracy: 0.7917 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 299/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.4877 - val_accuracy: 0.7465\n",
      "Epoch 300/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4400 - accuracy: 0.8021 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
      "Epoch 301/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7500\n",
      "Epoch 302/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4431 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7535\n",
      "Epoch 303/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.4867 - val_accuracy: 0.7396\n",
      "Epoch 304/400\n",
      "288/288 [==============================] - 0s 64us/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.4874 - val_accuracy: 0.7465\n",
      "Epoch 305/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4503 - accuracy: 0.7917 - val_loss: 0.4868 - val_accuracy: 0.7465\n",
      "Epoch 306/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.4876 - val_accuracy: 0.7465\n",
      "Epoch 307/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7500\n",
      "Epoch 308/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4536 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
      "Epoch 309/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.4875 - val_accuracy: 0.7500\n",
      "Epoch 310/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7431\n",
      "Epoch 311/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4421 - accuracy: 0.8021 - val_loss: 0.4875 - val_accuracy: 0.7431\n",
      "Epoch 312/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4509 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 313/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4487 - accuracy: 0.7917 - val_loss: 0.4875 - val_accuracy: 0.7431\n",
      "Epoch 314/400\n",
      "288/288 [==============================] - 0s 63us/step - loss: 0.4460 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7500\n",
      "Epoch 315/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7500\n",
      "Epoch 316/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4537 - accuracy: 0.7847 - val_loss: 0.4871 - val_accuracy: 0.7396\n",
      "Epoch 317/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.4883 - val_accuracy: 0.7535\n",
      "Epoch 318/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4539 - accuracy: 0.7917 - val_loss: 0.4869 - val_accuracy: 0.7431\n",
      "Epoch 319/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 320/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4527 - accuracy: 0.7917 - val_loss: 0.4896 - val_accuracy: 0.7465\n",
      "Epoch 321/400\n",
      "288/288 [==============================] - 0s 71us/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7535\n",
      "Epoch 322/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.4873 - val_accuracy: 0.7431\n",
      "Epoch 323/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4462 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
      "Epoch 324/400\n",
      "288/288 [==============================] - 0s 71us/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.4879 - val_accuracy: 0.7465\n",
      "Epoch 325/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4419 - accuracy: 0.7986 - val_loss: 0.4874 - val_accuracy: 0.7396\n",
      "Epoch 326/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.4883 - val_accuracy: 0.7500\n",
      "Epoch 327/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4513 - accuracy: 0.7882 - val_loss: 0.4897 - val_accuracy: 0.7465\n",
      "Epoch 328/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7396\n",
      "Epoch 329/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.4882 - val_accuracy: 0.7465\n",
      "Epoch 330/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4412 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7431\n",
      "Epoch 331/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4563 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7431\n",
      "Epoch 332/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7431\n",
      "Epoch 333/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.4902 - val_accuracy: 0.7465\n",
      "Epoch 334/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4574 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7465\n",
      "Epoch 335/400\n",
      "288/288 [==============================] - 0s 71us/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7396\n",
      "Epoch 336/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
      "Epoch 337/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4489 - accuracy: 0.7847 - val_loss: 0.4888 - val_accuracy: 0.7535\n",
      "Epoch 338/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4884 - val_accuracy: 0.7465\n",
      "Epoch 339/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.4890 - val_accuracy: 0.7535\n",
      "Epoch 340/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4554 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7431\n",
      "Epoch 341/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4525 - accuracy: 0.7882 - val_loss: 0.4889 - val_accuracy: 0.7535\n",
      "Epoch 342/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4519 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7465\n",
      "Epoch 343/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 344/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4482 - accuracy: 0.7986 - val_loss: 0.4881 - val_accuracy: 0.7431\n",
      "Epoch 345/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.4882 - val_accuracy: 0.7431\n",
      "Epoch 346/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4472 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7431\n",
      "Epoch 347/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7465\n",
      "Epoch 348/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4636 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7465\n",
      "Epoch 349/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4377 - accuracy: 0.7882 - val_loss: 0.4880 - val_accuracy: 0.7465\n",
      "Epoch 350/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.4882 - val_accuracy: 0.7465\n",
      "Epoch 351/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4485 - accuracy: 0.7917 - val_loss: 0.4879 - val_accuracy: 0.7431\n",
      "Epoch 352/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4570 - accuracy: 0.7847 - val_loss: 0.4899 - val_accuracy: 0.7465\n",
      "Epoch 353/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4509 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7465\n",
      "Epoch 354/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4477 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7465\n",
      "Epoch 355/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4532 - accuracy: 0.7917 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
      "Epoch 356/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.4881 - val_accuracy: 0.7431\n",
      "Epoch 357/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4508 - accuracy: 0.7917 - val_loss: 0.4884 - val_accuracy: 0.7465\n",
      "Epoch 358/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4463 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7465\n",
      "Epoch 359/400\n",
      "288/288 [==============================] - 0s 642us/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.4877 - val_accuracy: 0.7431\n",
      "Epoch 360/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7465\n",
      "Epoch 361/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4396 - accuracy: 0.7882 - val_loss: 0.4878 - val_accuracy: 0.7396\n",
      "Epoch 362/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4556 - accuracy: 0.7917 - val_loss: 0.4903 - val_accuracy: 0.7465\n",
      "Epoch 363/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7431\n",
      "Epoch 364/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4372 - accuracy: 0.7986 - val_loss: 0.4888 - val_accuracy: 0.7465\n",
      "Epoch 365/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.4886 - val_accuracy: 0.7465\n",
      "Epoch 366/400\n",
      "288/288 [==============================] - 0s 64us/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.4880 - val_accuracy: 0.7431\n",
      "Epoch 367/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.4898 - val_accuracy: 0.7500\n",
      "Epoch 368/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.4882 - val_accuracy: 0.7396\n",
      "Epoch 369/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4501 - accuracy: 0.7882 - val_loss: 0.4882 - val_accuracy: 0.7396\n",
      "Epoch 370/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4387 - accuracy: 0.7847 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 371/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.4891 - val_accuracy: 0.7465\n",
      "Epoch 372/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4466 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 373/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4356 - accuracy: 0.7917 - val_loss: 0.4890 - val_accuracy: 0.7465\n",
      "Epoch 374/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4599 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7431\n",
      "Epoch 375/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4402 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7535\n",
      "Epoch 376/400\n",
      "288/288 [==============================] - 0s 69us/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7396\n",
      "Epoch 377/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.4894 - val_accuracy: 0.7500\n",
      "Epoch 378/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4525 - accuracy: 0.7986 - val_loss: 0.4897 - val_accuracy: 0.7535\n",
      "Epoch 379/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.4889 - val_accuracy: 0.7431\n",
      "Epoch 380/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7396\n",
      "Epoch 381/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.4886 - val_accuracy: 0.7465\n",
      "Epoch 382/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4533 - accuracy: 0.7882 - val_loss: 0.4910 - val_accuracy: 0.7465\n",
      "Epoch 383/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7500\n",
      "Epoch 384/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.4881 - val_accuracy: 0.7396\n",
      "Epoch 385/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4424 - accuracy: 0.8021 - val_loss: 0.4886 - val_accuracy: 0.7431\n",
      "Epoch 386/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.4901 - val_accuracy: 0.7500\n",
      "Epoch 387/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4368 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 388/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.4899 - val_accuracy: 0.7535\n",
      "Epoch 389/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4891 - val_accuracy: 0.7465\n",
      "Epoch 390/400\n",
      "288/288 [==============================] - 0s 70us/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.4886 - val_accuracy: 0.7396\n",
      "Epoch 391/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4417 - accuracy: 0.7951 - val_loss: 0.4883 - val_accuracy: 0.7396\n",
      "Epoch 392/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4424 - accuracy: 0.8021 - val_loss: 0.4897 - val_accuracy: 0.7500\n",
      "Epoch 393/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.4912 - val_accuracy: 0.7465\n",
      "Epoch 394/400\n",
      "288/288 [==============================] - 0s 66us/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 395/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.4899 - val_accuracy: 0.7465\n",
      "Epoch 396/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4518 - accuracy: 0.7882 - val_loss: 0.4892 - val_accuracy: 0.7465\n",
      "Epoch 397/400\n",
      "288/288 [==============================] - 0s 67us/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7396\n",
      "Epoch 398/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4462 - accuracy: 0.7847 - val_loss: 0.4893 - val_accuracy: 0.7500\n",
      "Epoch 399/400\n",
      "288/288 [==============================] - 0s 68us/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7431\n",
      "Epoch 400/400\n",
      "288/288 [==============================] - 0s 65us/step - loss: 0.4398 - accuracy: 0.7812 - val_loss: 0.4885 - val_accuracy: 0.7431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ffa3724efd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Keras DNN Model\n",
    "#from tensorflow.contrib import keras\n",
    "#from keras import models, layers, losses, optimizers, metrics\n",
    "import keras\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Hyperparameters\n",
    "hold_prob = 0.01\n",
    "beta = 1e-8\n",
    "alpha = 0.05\n",
    "lr_decay = 0.01\n",
    "iterations = 400\n",
    "validation_split = 0.5\n",
    "opt_momentum = 0.9 # (Use only for SGD)\n",
    "batch_size = 32\n",
    "\n",
    "# Optimizer\n",
    "opt = optimizers.SGD(lr=alpha, decay=lr_decay, momentum=opt_momentum, nesterov=True)\n",
    "\n",
    "# First Layer\n",
    "model.add(layers.Dense(input_dim=8, units=8, activation='relu'))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(layers.Dense(units=8, activation='relu', kernel_regularizer=keras.regularizers.l2(beta)))\n",
    "model.add(layers.Dropout(hold_prob))\n",
    "\n",
    "model.add(layers.Dense(units=8, activation='relu', kernel_regularizer=keras.regularizers.l2(beta)))\n",
    "model.add(layers.Dropout(hold_prob))\n",
    "\n",
    "model.add(layers.Dense(units=8, activation='relu', kernel_regularizer=keras.regularizers.l2(beta)))\n",
    "model.add(layers.Dropout(hold_prob))\n",
    "\n",
    "# Output Layer\n",
    "model.add(layers.Dense(units=2, activation='softmax'))\n",
    "\n",
    "# Compiling the Model\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(x=scaled_x_train, y=y_train, epochs=iterations, validation_split=validation_split, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       130\n",
      "           1       0.62      0.58      0.60        62\n",
      "\n",
      "    accuracy                           0.75       192\n",
      "   macro avg       0.71      0.71      0.71       192\n",
      "weighted avg       0.75      0.75      0.75       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(scaled_x_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FINRA Py3.6",
   "language": "python",
   "name": "finra_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
